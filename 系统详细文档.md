# LLMæ™ºèƒ½ä½“äººç±»è¡Œä¸ºæ¨¡æ‹Ÿç³»ç»Ÿ - è¯¦ç»†æŠ€æœ¯æ–‡æ¡£ v2.0

## ğŸ“‹ é¡¹ç›®æ¦‚è¿°

æœ¬ç³»ç»Ÿæ˜¯ä¸€ä¸ªåŸºäºLangChainçš„å¤§è¯­è¨€æ¨¡å‹æ™ºèƒ½ä½“ç³»ç»Ÿï¼Œä¸“é—¨ç”¨äºæ¨¡æ‹Ÿå…·æœ‰ä¸åŒå¿ƒç†ç‰¹å¾çš„äººç±»åœ¨AIè¾…åŠ©è´·æ¬¾å®¡æ‰¹ä»»åŠ¡ä¸­çš„å†³ç­–è¡Œä¸ºã€‚ç³»ç»Ÿå®ç°äº†å¤æ‚çš„å¿ƒç†å­¦ç†è®ºï¼ŒåŒ…æ‹¬åŒè¿‡ç¨‹ç†è®ºï¼ˆFast vs Slow Thinkingï¼‰ã€è®¤çŸ¥éœ€æ±‚é‡è¡¨ï¼ˆNCS-18ï¼‰ã€è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨ï¼ˆGSE-10ï¼‰ç­‰ï¼Œèƒ½å¤Ÿç”Ÿæˆ81ç§ä¸åŒçš„äººæ ¼ç»„åˆè¿›è¡Œå†³ç­–è¡Œä¸ºç ”ç©¶ã€‚

### ğŸ¯ æ ¸å¿ƒåŠŸèƒ½ç‰¹æ€§
- ğŸ§  **åŒè¿‡ç¨‹æ€ç»´æ¨¡æ‹Ÿ**ï¼šSystem 1å¿«æ€è€ƒ vs System 2æ…¢æ€è€ƒçš„å®Œæ•´å®ç°
- ğŸ‘¥ **å¤šç»´åº¦äººæ ¼å»ºæ¨¡**ï¼šä¸“ä¸šæ°´å¹³ Ã— AIä¿¡ä»»åº¦ Ã— è®¤çŸ¥éœ€æ±‚ Ã— è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ
- ğŸ¯ **å¿ƒç†é‡è¡¨é›†æˆ**ï¼šNCS-18è®¤çŸ¥éœ€æ±‚é‡è¡¨ + GSE-10è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨çš„å®Œæ•´å®ç°
- ğŸ¤– **AIå»ºè®®è¯„ä¼°æœºåˆ¶**ï¼šåŸºäºå¿ƒç†ç‰¹å¾çš„AIæ¨èæ¥å—/æ‹’ç»è¡Œä¸ºæ¨¡æ‹Ÿ
- ğŸ“Š **å®Œæ•´å®éªŒæµç¨‹**ï¼šä»æ•°æ®é¢„å¤„ç†åˆ°ç»“æœåˆ†æçš„ç«¯åˆ°ç«¯ç³»ç»Ÿ
- ğŸ­ **å¿ƒç†å­¦çœŸå®æ€§**ï¼šå¢å¼ºçš„æç¤ºå·¥ç¨‹ç³»ç»Ÿï¼Œå®ç°çœŸå®çš„äººç±»å¿ƒç†è¡Œä¸ºæ¨¡æ‹Ÿ

### ğŸ†• æœ€æ–°ä¼˜åŒ–äº®ç‚¹
- **å¿ƒç†å­¦é©±åŠ¨çš„æç¤ºå·¥ç¨‹**ï¼šè¯¦ç»†çš„äººæ ¼èº«ä»½è®¾å®šå’Œæƒ…æ„ŸçœŸå®æ€§
- **åŠ¨æ€å¿ƒç†çŠ¶æ€é€‚åº”**ï¼šåŸºäºå¿ƒç†ç‰¹å¾çš„å®æ—¶å†³ç­–è°ƒæ•´
- **å¢å¼ºçš„è¡Œä¸ºå·®å¼‚åŒ–**ï¼š81ç§äººæ ¼ç»„åˆå±•ç°æ˜¾è‘—ä¸åŒçš„å†³ç­–æ¨¡å¼
- **æƒ…æ„Ÿä¸è®¤çŸ¥æ•´åˆ**ï¼šå°†æƒ…æ„Ÿååº”ã€å†…åœ¨å†²çªã€ä¿¡å¿ƒæ°´å¹³å®Œæ•´æ•´åˆ

---

## ğŸ—ï¸ ç³»ç»Ÿæ¶æ„

### æ¶æ„æ¦‚è§ˆå›¾
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   ä¸“ä¸šæ°´å¹³       â”‚    â”‚   AIä¿¡ä»»åº¦      â”‚    â”‚   å»ºè®®é‡‡çº³      â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚                 â”‚
â”‚ â€¢ æ–°æ‰‹(1ä¸ªæœˆ)   â”‚    â”‚ â€¢ éå¸¸ä¸ä¿¡ä»»(-2)â”‚    â”‚ â€¢ æ¥å—AIå»ºè®®    â”‚
â”‚ â€¢ ä¸­çº§(2å¹´)     â”‚    â”‚ â€¢ ä¸­ç«‹(0)       â”‚    â”‚ â€¢ æ‹’ç»AIå»ºè®®    â”‚
â”‚ â€¢ ä¸“å®¶(10å¹´+)   â”‚    â”‚ â€¢ éå¸¸ä¿¡ä»»(+2)  â”‚    â”‚                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚   è®¤çŸ¥èƒ½åŠ›ä¸æ€ç»´æ¨¡å¼             â”‚
                â”‚                                 â”‚
                â”‚ å¿«æ€è€ƒ(System1)  æ…¢æ€è€ƒ(System2)â”‚
                â”‚ â€¢ ä»»åŠ¡ç®€åŒ–       â€¢ è®°å¿†æ£€ç´¢     â”‚
                â”‚ â€¢ ç›´è§‰åˆ¤æ–­       â€¢ åæ€åˆ†æ     â”‚
                â”‚                  â€¢ é€»è¾‘æ¨ç†     â”‚
                â”‚                  â€¢ è®¡åˆ’åˆ¶å®š     â”‚
                â”‚                  â€¢ å¿ƒç†ç†è®º     â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚     å¿ƒç†é‡è¡¨ç³»ç»Ÿ                 â”‚
                â”‚                                 â”‚
                â”‚  NCS-18        GSE-10          â”‚
                â”‚ â€¢ è®¤çŸ¥éœ€æ±‚      â€¢ è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ    â”‚
                â”‚ â€¢ 18é¢˜é‡è¡¨      â€¢ 10é¢˜é‡è¡¨      â”‚
                â”‚ â€¢ åå‘è®¡åˆ†      â€¢ 4ç‚¹è¯„åˆ†       â”‚
                â”‚ â€¢ é«˜ä¸­ä½çº§åˆ«    â€¢ é«˜ä¸­ä½çº§åˆ«    â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### æ ¸å¿ƒç»„ä»¶å…³ç³»
```python
HumanBehaviorSimulation (ä¸»æ§åˆ¶å™¨)
â”œâ”€â”€ LoanApprovalModel (MLæ¨¡å‹)
â”‚   â”œâ”€â”€ RandomForestClassifier (éšæœºæ£®æ—)
â”‚   â”œâ”€â”€ ç‰¹å¾é¢„å¤„ç†ç®¡é“
â”‚   â””â”€â”€ é¢„æµ‹ç½®ä¿¡åº¦è®¡ç®—
â”œâ”€â”€ PersonaAgent (æ™ºèƒ½ä½“)
â”‚   â”œâ”€â”€ å¢å¼ºçš„å¿ƒç†å­¦æç¤ºå·¥ç¨‹ç³»ç»Ÿ
â”‚   â”œâ”€â”€ ThinkingModeController (æ€ç»´æ¨¡å¼æ§åˆ¶å™¨)
â”‚   â”‚   â”œâ”€â”€ FastThinkingAgent (å¿«æ€è€ƒæ™ºèƒ½ä½“)
â”‚   â”‚   â””â”€â”€ SlowThinkingAgent (æ…¢æ€è€ƒæ™ºèƒ½ä½“)
â”‚   â””â”€â”€ PersonaConfig (äººæ ¼é…ç½®)
â”‚       â”œâ”€â”€ NeedForCognitionScale (è®¤çŸ¥éœ€æ±‚é‡è¡¨)
â”‚       â”œâ”€â”€ GeneralSelfEfficacyScale (è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨)
â”‚       â””â”€â”€ å¿ƒç†ç‰¹å¾åŠ¨æ€é€‚åº”ç³»ç»Ÿ
â””â”€â”€ ç»“æœåˆ†æä¸å­˜å‚¨
    â”œâ”€â”€ å®æ—¶è¿›åº¦ç›‘æ§
    â”œâ”€â”€ å¿ƒç†æ¨¡å¼åˆ†æ
    â””â”€â”€ å†³ç­–è¡Œä¸ºç»Ÿè®¡
```

---

## ğŸ“ æ ¸å¿ƒæ–‡ä»¶ç»“æ„

### ä¸»è¦ä»£ç æ–‡ä»¶
- **`main.py`** - ä¸»ç¨‹åºå…¥å£ï¼Œå®éªŒæ§åˆ¶å™¨ï¼Œè¿›åº¦ç›‘æ§
- **`ml_model.py`** - æœºå™¨å­¦ä¹ æ¨¡å‹ï¼Œæä¾›AIå†³ç­–åŸºçº¿
- **`persona_config.py`** - äººæ ¼é…ç½®å’Œå¿ƒç†ç‰¹å¾å®šä¹‰
- **`psychological_scales.py`** - å¿ƒç†å­¦é‡è¡¨å®Œæ•´å®ç°
- **`thinking_modes.py`** - åŒè¿‡ç¨‹æ€ç»´æ¨¡å¼å®ç°
- **`agents/persona_agent.py`** - å¢å¼ºçš„äººæ ¼åŒ–æ™ºèƒ½ä½“å®ç°

### é…ç½®å’Œæ•°æ®æ–‡ä»¶
- **`config/personas.json`** - ç”Ÿæˆçš„81ç§äººæ ¼é…ç½®
- **`data/loan_approval_dataset 2.csv`** - è®­ç»ƒæ•°æ®é›†
- **`test_data.csv`** - æµ‹è¯•æ¡ˆä¾‹æ•°æ®
- **`loan_model.pkl`** - è®­ç»ƒå¥½çš„éšæœºæ£®æ—æ¨¡å‹

### è¾“å‡ºæ–‡ä»¶
- **`results/simulation_results_*.csv`** - è¯¦ç»†æ¨¡æ‹Ÿç»“æœ
- **`results/analysis_*.json`** - èšåˆåˆ†æç»“æœ

---

## ğŸ§  å¿ƒç†å­¦ç†è®ºå®ç°

### 1. åŒè¿‡ç¨‹ç†è®º (Dual Process Theory)

#### å¿«æ€è€ƒ (System 1) - `FastThinkingAgent`
```python
class FastThinkingAgent:
    """å®ç°å¿«æ€è€ƒçš„æ™ºèƒ½ä½“ï¼Œé€šè¿‡ä»»åŠ¡ç®€åŒ–å’Œå¿ƒç†å­¦é©±åŠ¨çš„ç›´è§‰åˆ¤æ–­"""
    
    def simplify_task(self, loan_application: LoanApplication) -> TaskSimplification:
        """å°†å¤æ‚çš„è´·æ¬¾å®¡æ‰¹ä»»åŠ¡ç®€åŒ–ä¸ºå…³é”®æŒ‡æ ‡ï¼Œç»“åˆå¿ƒç†ç‰¹å¾"""
        
        # è·å–å¿ƒç†ç‰¹å¾è¿›è¡Œä¸Šä¸‹æ–‡åŒ–å¿«æ€è€ƒ
        gse_level = self.persona_config.get_gse_level()
        ncs_level = self.persona_config.get_ncs_level()
        
        # åˆ›å»ºå¿«æ€è€ƒå¿ƒç†çŠ¶æ€ä¸Šä¸‹æ–‡
        fast_thinking_context = {
            ScaleLevel.HIGH: "ä½ å¯¹å¿«é€Ÿè¯†åˆ«å…³é”®å› ç´ å¾ˆæœ‰ä¿¡å¿ƒï¼Œä½†è¦é¿å…è¿‡åº¦æ€è€ƒã€‚",
            ScaleLevel.MEDIUM: "ä½ å¯¹å¿«é€Ÿè¯„ä¼°æ„Ÿåˆ°åˆç†è‡ªä¿¡ã€‚", 
            ScaleLevel.LOW: "ä½ å¯¹å¿«é€Ÿå†³ç­–æ„Ÿåˆ°å‹åŠ›ï¼Œæ‹…å¿ƒé—æ¼é‡è¦ç»†èŠ‚ã€‚"
        }
        
        cognition_context = {
            ScaleLevel.HIGH: "å³ä½¿å¿«é€Ÿæ€è€ƒï¼Œä½ ä¹Ÿå¿ä¸ä½æ³¨æ„åˆ°å¤šä¸ªå› ç´  - ä½†å¼ºè¿«è‡ªå·±ä¸“æ³¨äºæœ€æ˜æ˜¾çš„ã€‚",
            ScaleLevel.MEDIUM: "ä½ åœ¨å¿«é€Ÿæ€è€ƒæ—¶è‡ªç„¶å¹³è¡¡ç®€å•æ€§å’Œå……åˆ†åˆ†æã€‚",
            ScaleLevel.LOW: "ä½ åå¥½è¿™ç§å¿«é€Ÿç®€åŒ–çš„æ–¹æ³•ï¼Œä¸“æ³¨äºåŸºç¡€è¦ç´ æ„Ÿåˆ°èˆ’é€‚ã€‚"
        }
        
        prompt = f"""
        ä½ æ˜¯ä¸€ä¸ªéœ€è¦å¿«é€Ÿå†³ç­–è€Œä¸èƒ½è¿‡åº¦æ€è€ƒçš„è´·æ¬¾å®¡æ‰¹å‘˜ã€‚æ—¶é—´å‹åŠ›è¿«ä½¿ä½ ç®€åŒ–ã€‚
        
        è´·æ¬¾ç”³è¯·æ•°æ®ï¼š
        {loan_data}
        
        ä½ çš„å¿ƒç†çŠ¶æ€ï¼š
        {fast_thinking_context[gse_level]}
        {cognition_context[ncs_level]}
        
        ä»»åŠ¡ï¼šå°†è¿™ä¸ªè´·æ¬¾å®¡æ‰¹å¿«é€Ÿç®€åŒ–ä¸ºæœ€å…³é”®çš„å› ç´ ï¼Œæ”¯æŒå³æ—¶ç›´è§‰ååº”å†³ç­–ã€‚
        
        åƒæ—¶é—´å‹åŠ›ä¸‹çš„äººç±»ä¸€æ ·æ€è€ƒ - ä½ æœ¬èƒ½åœ°é¦–å…ˆå…³æ³¨ä»€ä¹ˆï¼Ÿ
        
        æä¾›ï¼š
        1. ç®€åŒ–ä»»åŠ¡ï¼šä¸€å¥æ¸…æ¥šæè¿°ä½ éœ€è¦å†³å®šä»€ä¹ˆ
        2. å…³é”®å› ç´ ï¼šä½ é¦–å…ˆæ£€æŸ¥çš„2-3ä¸ªæœ€æ˜æ˜¾æŒ‡æ ‡
        3. ç®€åŒ–æ¨ç†ï¼šä¸ºä»€ä¹ˆé€‰æ‹©è¿™äº›å› ç´ è€Œä¸æ˜¯å…¶ä»–
        
        è¦çœŸå®åæ˜ ä½ çš„å¿ƒç†æ¡£æ¡ˆ - å±•ç¤ºä½ çš„ä¿¡å¿ƒæ°´å¹³å’Œæ€ç»´é£æ ¼å¦‚ä½•å½±å“å¿«é€Ÿå†³ç­–ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return self._parse_task_simplification(response.content)
    
    def make_fast_decision(self, task_simplification: TaskSimplification, 
                          loan_application: LoanApplication) -> CognitionState:
        """åŸºäºå¿ƒç†å­¦çœŸå®æ€§åšå‡ºå¿«é€Ÿå†³ç­–"""
        
        # è·å–äººæ ¼ç‰¹å¾
        gse_level = self.persona_config.get_gse_level()
        ncs_level = self.persona_config.get_ncs_level()
        
        # åˆ›å»ºå¿«é€Ÿå†³ç­–ä¸Šä¸‹æ–‡
        confidence_context = {
            ScaleLevel.HIGH: "ä½ ç›¸ä¿¡è‡ªå·±çš„ç›´è§‰ï¼Œå¯¹å¿«é€Ÿå†³ç­–æ„Ÿåˆ°è‡ªä¿¡ã€‚",
            ScaleLevel.MEDIUM: "å½“å› ç´ æ¸…æ™°æ—¶ï¼Œä½ å¯¹å¿«é€Ÿå†³ç­–æ„Ÿåˆ°åˆç†è‡ªä¿¡ã€‚",
            ScaleLevel.LOW: "ä½ å¯¹å¿«é€Ÿå†³ç­–æ„Ÿåˆ°æœ‰äº›ç„¦è™‘ï¼Œä½†è®¤è¯†åˆ°éœ€è¦å‘å‰æ¨è¿›ã€‚"
        }
        
        thinking_context = {
            ScaleLevel.HIGH: "ä½ å…‹åˆ¶æ·±å…¥æŒ–æ˜çš„å†²åŠ¨ï¼Œå¼ºè¿«è‡ªå·±åšæŒç›´è§‰ååº”ã€‚",
            ScaleLevel.MEDIUM: "ä½ å¯¹è¿™ä¸ªæ°´å¹³çš„åˆ†ææ„Ÿåˆ°èˆ’é€‚ã€‚",
            ScaleLevel.LOW: "ä½ å› ä¿æŒåˆ†æç®€å•ç›´æ¥è€Œæ„Ÿåˆ°å®‰å¿ƒã€‚"
        }
        
        prompt = f"""
        åŸºäºä½ çš„ç®€åŒ–åˆ†æï¼Œä½ éœ€è¦åšå‡ºå¿«é€Ÿå†³ç­–ã€‚ä¸å…è®¸è¿‡åº¦æ€è€ƒï¼
        
        ç®€åŒ–ä»»åŠ¡ï¼š{task_simplification.simplified_task}
        å…³é”®å› ç´ ï¼š{', '.join(task_simplification.key_factors)}
        æ¨ç†ï¼š{task_simplification.simplification_reasoning}
        
        ä½ çš„å¿ƒç†çŠ¶æ€ï¼š
        {confidence_context[gse_level]}
        {thinking_context[ncs_level]}
        
        ç»™å‡ºä½ çš„å³æ—¶ç›´è§‰ååº”ï¼š
        
        å†³ç­–ï¼š[Approve/Reject]
        ä¿¡å¿ƒï¼š[X]%
        å¿«é€Ÿæ¨ç†ï¼š[ä¸€å¥è¯è§£é‡Šä½ çš„ç›´è§‰ååº”]
        
        è¦çœŸå®åæ˜ ä½ çš„å¿ƒç†æ¡£æ¡ˆ - å±•ç¤ºä½ çš„ä¿¡å¿ƒå’Œæ€ç»´é£æ ¼å¦‚ä½•å½±å“è¿™ä¸ªå¿«é€Ÿå†³ç­–ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        response_text = response.content
        
        # å¢å¼ºæå–
        decision = self._extract_decision_from_text(response_text)
        confidence = self._extract_confidence(response_text)
        
        return CognitionState(
            initial_decision=decision,
            confidence_level=confidence,
            reasoning_process=[f"[å¿«æ€è€ƒ] {response_text}"],
            memory_items=task_simplification.key_factors,
            reflection_points=["å¿«é€Ÿå†³ç­– - ç”±äºæ—¶é—´å‹åŠ›çš„æœ€å°åæ€"]
        )
```

#### æ…¢æ€è€ƒ (System 2) - `SlowThinkingAgent`
```python
class SlowThinkingAgent:
    """å®ç°æ…¢æ€è€ƒçš„å¤šæ™ºèƒ½ä½“ç³»ç»Ÿï¼ŒåŒ…å«5ä¸ªæ·±åº¦åˆ†æé˜¶æ®µ"""
    
    def engage_slow_thinking(self, loan_application: LoanApplication) -> SlowThinkingResult:
        """æ‰§è¡Œæ·±åº¦å¤šæ™ºèƒ½ä½“åˆ†æè¿‡ç¨‹"""
        
        loan_data = json.dumps(loan_application.to_dict(), indent=2)
        
        # 5ä¸ªæ·±åº¦åˆ†æé˜¶æ®µ - æ¯ä¸ªéƒ½ç»“åˆå¿ƒç†ç‰¹å¾
        memory_analysis = self._memory_analysis(loan_data)
        reflection_analysis = self._reflection_analysis(loan_data, memory_analysis)
        reasoning_analysis = self._reasoning_analysis(loan_data, memory_analysis, reflection_analysis)
        planning_analysis = self._planning_analysis(loan_data, reasoning_analysis)
        theory_of_mind_analysis = self._theory_of_mind_analysis(loan_data, reasoning_analysis)
        final_synthesis = self._final_synthesis(
            loan_data, memory_analysis, reflection_analysis, 
            reasoning_analysis, planning_analysis, theory_of_mind_analysis
        )
        
        return SlowThinkingResult(
            memory_analysis=memory_analysis,
            reflection_analysis=reflection_analysis,
            reasoning_analysis=reasoning_analysis,
            planning_analysis=planning_analysis,
            theory_of_mind_analysis=theory_of_mind_analysis,
            final_synthesis=final_synthesis
        )
    
    def _memory_analysis(self, loan_data: str) -> str:
        """åŸºäºè¿‡å¾€ç»éªŒå’ŒçŸ¥è¯†çš„åˆ†æ"""
        prompt = f"""
        ä½œä¸ºè´·æ¬¾å®¡æ‰¹å‘˜ï¼Œå›æƒ³ä½ è¿‡å¾€å¤„ç†ç±»ä¼¼è´·æ¬¾ç”³è¯·çš„ç»éªŒã€‚
        
        è´·æ¬¾ç”³è¯·ï¼š
        {loan_data}
        
        åŸºäºä½ çš„ç»éªŒå’ŒçŸ¥è¯†ï¼Œä½ è®°å¾—å“ªäº›ä¸æ­¤æ¡ˆä¾‹ç›¸å…³çš„æ¨¡å¼ï¼Ÿ
        ä½ ä¹‹å‰è§è¿‡ä»€ä¹ˆç±»ä¼¼æ¡ˆä¾‹ï¼Ÿ
        å®ƒä»¬çš„ç»“æœå¦‚ä½•ï¼Ÿ
        ä½ ä»ä¸­å­¦åˆ°äº†ä»€ä¹ˆé£é™©æŒ‡æ ‡ï¼Ÿ
        
        æä¾›åŸºäºè®°å¿†çš„è¯¦ç»†åˆ†æï¼ŒåŒ…æ‹¬å…·ä½“çš„ç»éªŒæ•™è®­ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
    
    def _reflection_analysis(self, loan_data: str, memory_analysis: str) -> str:
        """å¯¹åˆ†æè¿›è¡Œåæ€å¹¶è¯†åˆ«æ½œåœ¨åè§"""
        prompt = f"""
        ç°åœ¨åæ€ä½ åŸºäºè®°å¿†çš„åˆå§‹åˆ†æã€‚
        
        ä½ çš„è®°å¿†åˆ†æï¼š{memory_analysis}
        
        éœ€è¦è€ƒè™‘çš„é—®é¢˜ï¼š
        1. æˆ‘åœ¨åšä»€ä¹ˆå‡è®¾ï¼Ÿ
        2. ä»€ä¹ˆåè§å¯èƒ½å½±å“æˆ‘çš„åˆ¤æ–­ï¼Ÿ
        3. ä»€ä¹ˆé¢å¤–ä¿¡æ¯ä¼šæœ‰å¸®åŠ©ï¼Ÿ
        4. å¦‚æœæˆ‘é”™äº†ï¼Œæ½œåœ¨åæœæ˜¯ä»€ä¹ˆï¼Ÿ
        5. æˆ‘çš„ä¸“ä¸šæ°´å¹³å¦‚ä½•å½±å“è¿™ä¸ªè¯„ä¼°ï¼Ÿ
        
        æä¾›æ·±æ€ç†Ÿè™‘çš„åæ€ï¼ŒæŒ‘æˆ˜ä½ çš„åˆå§‹åˆ†æã€‚
        å±•ç¤ºä½ çš„è‡ªæˆ‘æ•ˆèƒ½æ„Ÿæ°´å¹³å¦‚ä½•å½±å“ä½ å¯¹è‡ªå·±åˆ¤æ–­çš„ä¿¡å¿ƒã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
    
    def _reasoning_analysis(self, loan_data: str, memory_analysis: str, reflection_analysis: str) -> str:
        """æ·±åº¦æ€ç»´é“¾æ¨ç†"""
        prompt = f"""
        ç°åœ¨å¯¹è¿™ä¸ªè´·æ¬¾ç”³è¯·è¿›è¡Œé€æ­¥é€»è¾‘æ¨ç†ã€‚
        
        è´·æ¬¾æ•°æ®ï¼š{loan_data}
        è®°å¿†åˆ†æï¼š{memory_analysis}
        åæ€ï¼š{reflection_analysis}
        
        åº”ç”¨æ€ç»´é“¾æ¨ç†ï¼š
        1. å…³é”®é£é™©å› ç´ æ˜¯ä»€ä¹ˆï¼Ÿ
        2. è¿™äº›å› ç´ å¦‚ä½•ç›¸äº’ä½œç”¨ï¼Ÿ
        3. åŸºäºæ¯ä¸ªå› ç´ ï¼Œè¿çº¦æ¦‚ç‡æ˜¯å¤šå°‘ï¼Ÿ
        4. è¿™äº›å› ç´ å¦‚ä½•ç»“åˆåˆ›é€ æ•´ä½“é£é™©ï¼Ÿ
        5. ä»€ä¹ˆè¯æ®æ”¯æŒæ‰¹å‡† vs æ‹’ç»ï¼Ÿ
        6. åŸºäºæˆ‘çš„ä¸“ä¸šæ°´å¹³ï¼Œæˆ‘èƒ½è¯†åˆ«å“ªäº›å¾®å¦™æ¨¡å¼ï¼Ÿ
        
        ç³»ç»Ÿåœ°é€æ­¥åˆ†æï¼Œå±•ç¤ºä½ çš„è®¤çŸ¥éœ€æ±‚æ°´å¹³å¦‚ä½•å½±å“åˆ†ææ·±åº¦ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
    
    def _planning_analysis(self, loan_data: str, reasoning_analysis: str) -> str:
        """è§„åˆ’å†³ç­–åˆ¶å®šæ–¹æ³•"""
        prompt = f"""
        åŸºäºä½ çš„æ¨ç†ï¼Œè§„åˆ’ä½ çš„å†³ç­–åˆ¶å®šæ–¹æ³•ã€‚
        
        æ¨ç†åˆ†æï¼š{reasoning_analysis}
        
        è€ƒè™‘ï¼š
        1. æˆ‘åº”è¯¥ä¼˜å…ˆè€ƒè™‘ä»€ä¹ˆå†³ç­–æ ‡å‡†ï¼Ÿ
        2. å¯èƒ½éœ€è¦ä»€ä¹ˆé¢å¤–æ£€æŸ¥æˆ–æ¡ä»¶ï¼Ÿ
        3. æˆ‘åº”è¯¥å¦‚ä½•æƒè¡¡ä¸åŒå› ç´ ï¼Ÿ
        4. æˆ‘çš„å†³ç­–åˆ¶å®šæ¡†æ¶æ˜¯ä»€ä¹ˆï¼Ÿ
        5. æˆ‘çš„è‡ªæˆ‘æ•ˆèƒ½æ„Ÿå¦‚ä½•å½±å“æˆ‘å¯¹å¤æ‚å†³ç­–çš„ä¿¡å¿ƒï¼Ÿ
        
        åˆ›å»ºåšå‡ºè¿™ä¸ªå†³ç­–çš„ç»“æ„åŒ–è®¡åˆ’ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
    
    def _theory_of_mind_analysis(self, loan_data: str, reasoning_analysis: str) -> str:
        """è€ƒè™‘å…¶ä»–è§‚ç‚¹å’Œåˆ©ç›Šç›¸å…³è€…è§†è§’"""
        prompt = f"""
        ç°åœ¨ä»å¤šä¸ªè§†è§’è€ƒè™‘è¿™ä¸ªè´·æ¬¾ç”³è¯·ã€‚
        
        æ¨ç†ï¼š{reasoning_analysis}
        
        è€ƒè™‘ä»¥ä¸‹è§†è§’ï¼š
        1. è´·æ¬¾ç”³è¯·äºº - ä»–ä»¬å¯èƒ½åœ¨æƒ³ä»€ä¹ˆ/æ„Ÿè§‰ä»€ä¹ˆï¼Ÿ
        2. é“¶è¡Œç®¡ç†å±‚ - ä»–ä»¬çš„æ‹…å¿§æ˜¯ä»€ä¹ˆï¼Ÿ
        3. ç›‘ç®¡æœºæ„ - å¯èƒ½å‡ºç°ä»€ä¹ˆåˆè§„é—®é¢˜ï¼Ÿ
        4. å…¶ä»–è´·æ¬¾å®¡æ‰¹å‘˜ - ä»–ä»¬å¯èƒ½å¦‚ä½•çœ‹å¾…è¿™ä¸ªæ¡ˆä¾‹ï¼Ÿ
        5. å¦‚æœæˆ‘æ˜¯å®¢æˆ·ï¼Œæˆ‘ä¼šå¦‚ä½•çœ‹å¾…è¿™ä¸ªå†³ç­–ï¼Ÿ
        
        è¿™äº›ä¸åŒè§‚ç‚¹å¦‚ä½•å½±å“å†³ç­–ï¼Ÿ
        ä½ çš„AIä¿¡ä»»æ°´å¹³å¦‚ä½•å½±å“ä½ å¯¹äººç±» vs ç®—æ³•åˆ¤æ–­çš„æƒè¡¡ï¼Ÿ
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
    
    def _final_synthesis(self, loan_data: str, memory_analysis: str, reflection_analysis: str,
                        reasoning_analysis: str, planning_analysis: str, theory_of_mind_analysis: str) -> str:
        """å°†æ‰€æœ‰åˆ†æç»¼åˆä¸ºæœ€ç»ˆå†³ç­–"""
        prompt = f"""
        ç°åœ¨å°†ä½ æ‰€æœ‰çš„åˆ†æç»¼åˆä¸ºå…¨é¢å†³ç­–ã€‚
        
        è®°å¿†åˆ†æï¼š{memory_analysis}
        åæ€ï¼š{reflection_analysis}
        æ¨ç†ï¼š{reasoning_analysis}
        è§„åˆ’ï¼š{planning_analysis}
        å¿ƒç†ç†è®ºï¼š{theory_of_mind_analysis}
        
        åŸºäºæ‰€æœ‰è¿™äº›æ·±åº¦æ€è€ƒï¼Œæä¾›ï¼š
        1. ä½ çš„æœ€ç»ˆå†³ç­– (Approve/Reject)
        2. ä½ çš„ä¿¡å¿ƒæ°´å¹³ (0-100%)
        3. æ•´åˆæ‰€æœ‰åˆ†æçš„å…¨é¢æ¨ç†
        4. å½±å“ä½ å†³ç­–çš„å…³é”®å› ç´ 
        5. ä»»ä½•å‰©ä½™çš„æ‹…å¿§æˆ–ä¸ç¡®å®šæ€§
        6. ä½ çš„å¿ƒç†æ¡£æ¡ˆå¦‚ä½•å¡‘é€ è¿™ä¸ªç»“è®º
        
        è¿™åº”è¯¥æ˜¯ç»è¿‡æ·±æ€ç†Ÿè™‘ã€æœ‰å……åˆ†ç†ç”±çš„å†³ç­–ï¼Œåæ˜ ä½ çš„ä¸“ä¸šæ°´å¹³å’Œå¿ƒç†ç‰¹å¾ã€‚
        """
        
        response = self.llm.invoke([HumanMessage(content=prompt)])
        return response.content
```

### 2. è®¤çŸ¥éœ€æ±‚é‡è¡¨ (NCS-18)

#### å®Œæ•´é‡è¡¨å®ç°
```python
class NeedForCognitionScale:
    """è®¤çŸ¥éœ€æ±‚é‡è¡¨ - è¡¡é‡ä¸ªä½“äº«å—å¤æ‚æ€è€ƒçš„å€¾å‘"""
    
    def __init__(self):
        # å®Œæ•´çš„18é¢˜NCSé‡è¡¨
        self.items = [
            ScaleItem(1, "æˆ‘æ›´å–œæ¬¢å¤æ‚çš„é—®é¢˜è€Œä¸æ˜¯ç®€å•çš„é—®é¢˜ã€‚", False),
            ScaleItem(2, "æˆ‘å–œæ¬¢æ‰¿æ‹…éœ€è¦å¤§é‡æ€è€ƒçš„è´£ä»»ã€‚", False),
            ScaleItem(3, "æ€è€ƒä¸æ˜¯æˆ‘è®¤ä¸ºæœ‰è¶£çš„äº‹æƒ…ã€‚", True),  # åå‘è®¡åˆ†
            ScaleItem(4, "æˆ‘å®æ„¿åšéœ€è¦å¾ˆå°‘æ€è€ƒçš„äº‹æƒ…ï¼Œä¹Ÿä¸æ„¿åšè‚¯å®šä¼šæŒ‘æˆ˜æˆ‘æ€ç»´èƒ½åŠ›çš„äº‹æƒ…ã€‚", True),
            ScaleItem(5, "æˆ‘è¯•å›¾é¢„æµ‹å¹¶é¿å…å¯èƒ½éœ€è¦æˆ‘æ·±å…¥æ€è€ƒæŸäº‹çš„æƒ…å†µã€‚", True),
            ScaleItem(6, "æˆ‘åœ¨é•¿æ—¶é—´è‰°éš¾æ€è€ƒä¸­æ‰¾åˆ°æ»¡è¶³æ„Ÿã€‚", False),
            ScaleItem(7, "æˆ‘åªåœ¨å¿…é¡»æ—¶æ‰åŠªåŠ›æ€è€ƒã€‚", True),
            ScaleItem(8, "æˆ‘æ›´å–œæ¬¢æ€è€ƒå°çš„æ—¥å¸¸é¡¹ç›®è€Œä¸æ˜¯é•¿æœŸé¡¹ç›®ã€‚", True),
            ScaleItem(9, "æˆ‘å–œæ¬¢ä¸€æ—¦å­¦ä¼šå°±ä¸éœ€è¦å¤ªå¤šæ€è€ƒçš„ä»»åŠ¡ã€‚", True),
            ScaleItem(10, "ä¾é æ€è€ƒè¾¾åˆ°é¡¶å³°çš„æƒ³æ³•å¯¹æˆ‘å¾ˆæœ‰å¸å¼•åŠ›ã€‚", False),
            ScaleItem(11, "æˆ‘çœŸæ­£äº«å—æ¶‰åŠä¸ºé—®é¢˜æ‰¾åˆ°æ–°è§£å†³æ–¹æ¡ˆçš„ä»»åŠ¡ã€‚", False),
            ScaleItem(12, "å­¦ä¹ æ–°çš„æ€è€ƒæ–¹å¼å¹¶ä¸ä¼šè®©æˆ‘å¾ˆå…´å¥‹ã€‚", True),
            ScaleItem(13, "æˆ‘æ›´å–œæ¬¢æˆ‘çš„ç”Ÿæ´»å……æ»¡å¿…é¡»è§£å†³çš„è°œé¢˜ã€‚", False),
            ScaleItem(14, "æŠ½è±¡æ€è€ƒçš„æ¦‚å¿µå¯¹æˆ‘å¾ˆæœ‰å¸å¼•åŠ›ã€‚", False),
            ScaleItem(15, "æˆ‘æ›´å–œæ¬¢æ™ºåŠ›æ€§ã€å›°éš¾ä¸”é‡è¦çš„ä»»åŠ¡ï¼Œè€Œä¸æ˜¯æœ‰äº›é‡è¦ä½†ä¸éœ€è¦å¤ªå¤šæ€è€ƒçš„ä»»åŠ¡ã€‚", False),
            ScaleItem(16, "å®Œæˆéœ€è¦å¤§é‡è„‘åŠ›åŠ³åŠ¨çš„ä»»åŠ¡åï¼Œæˆ‘æ„Ÿåˆ°çš„æ˜¯è§£è„±è€Œä¸æ˜¯æ»¡è¶³ã€‚", True),
            ScaleItem(17, "å¯¹æˆ‘æ¥è¯´ï¼Œåªè¦èƒ½å®Œæˆå·¥ä½œå°±å¤Ÿäº†ï¼›æˆ‘ä¸å…³å¿ƒå®ƒå¦‚ä½•æˆ–ä¸ºä»€ä¹ˆèµ·ä½œç”¨ã€‚", True),
            ScaleItem(18, "å³ä½¿é—®é¢˜ä¸ç›´æ¥å½±å“æˆ‘ï¼Œæˆ‘é€šå¸¸ä¹Ÿä¼šæ€è€ƒè¿™äº›é—®é¢˜ã€‚", False)
        ]
    
    def calculate_score(self, responses: List[ScaleResponse]) -> ScaleResult:
        """è®¡ç®—NCSæ€»åˆ†å¹¶ç¡®å®šæ°´å¹³"""
        total_score = 0
        for response in responses:
            item = next((item for item in self.items if item.item_id == response.item_id), None)
            if item:
                if item.reverse_scored:
                    # åå‘è®¡åˆ†ï¼š1->5, 2->4, 3->3, 4->2, 5->1
                    score = 6 - response.response
                else:
                    score = response.response
                total_score += score
        
        # åŸºäºç ”ç©¶è§„èŒƒçš„åˆ†çº§æ ‡å‡†
        if total_score >= 75:
            level = ScaleLevel.HIGH
            interpretation = "é«˜è®¤çŸ¥éœ€æ±‚ - äº«å—æ€è€ƒå¹¶å¯»æ±‚å¤æ‚é—®é¢˜"
        elif total_score >= 60:
            level = ScaleLevel.MEDIUM
            interpretation = "ä¸­ç­‰è®¤çŸ¥éœ€æ±‚ - é€‚åº¦äº«å—æ€è€ƒ"
        else:
            level = ScaleLevel.LOW
            interpretation = "ä½è®¤çŸ¥éœ€æ±‚ - åå¥½ç®€å•ä»»åŠ¡ï¼Œé¿å…å¤æ‚æ€è€ƒ"
        
        return ScaleResult(
            scale_name="è®¤çŸ¥éœ€æ±‚é‡è¡¨ (NCS-18)",
            total_score=total_score,
            max_score=90, min_score=18,
            level=level, interpretation=interpretation
        )
    
    def generate_realistic_responses(self, target_level: ScaleLevel) -> List[ScaleResponse]:
        """ä¸ºç»™å®šç›®æ ‡æ°´å¹³ç”Ÿæˆç°å®çš„ååº”"""
        responses = []
        
        # å®šä¹‰ç›®æ ‡åˆ†æ•°èŒƒå›´
        if target_level == ScaleLevel.HIGH:
            target_range = (75, 85)
        elif target_level == ScaleLevel.MEDIUM:
            target_range = (60, 74)
        else:  # LOW
            target_range = (35, 59)
        
        target_score = random.randint(*target_range)
        avg_score_per_item = target_score / 18
        
        for item in self.items:
            # åœ¨ç›®æ ‡å¹³å‡å€¼å‘¨å›´ç”Ÿæˆå˜åŒ–çš„ååº”
            base_response = max(1, min(5, round(avg_score_per_item + random.uniform(-1, 1))))
            
            # åœ¨ç”Ÿæˆè¿‡ç¨‹ä¸­åº”ç”¨åå‘è®¡åˆ†é€»è¾‘
            if item.reverse_scored:
                # å¯¹äºåå‘é¢˜ç›®ï¼Œæˆ‘ä»¬æƒ³è¦ç›¸åçš„ååº”æ¨¡å¼
                if target_level == ScaleLevel.HIGH:
                    # é«˜NFCåº”è¯¥ä¸åŒæ„åå‘é¢˜ç›®
                    response = random.choice([1, 2, 3])
                elif target_level == ScaleLevel.LOW:
                    # ä½NFCåº”è¯¥åŒæ„åå‘é¢˜ç›®
                    response = random.choice([3, 4, 5])
                else:
                    # ä¸­ç­‰NFCåº”è¯¥ä¸­æ€§
                    response = random.choice([2, 3, 4])
            else:
                # å¯¹äºæ­£å¸¸é¢˜ç›®ï¼Œååº”ä¸ç›®æ ‡æ°´å¹³ä¸€è‡´
                if target_level == ScaleLevel.HIGH:
                    response = random.choice([3, 4, 5])
                elif target_level == ScaleLevel.LOW:
                    response = random.choice([1, 2, 3])
                else:
                    response = random.choice([2, 3, 4])
            
            responses.append(ScaleResponse(item_id=item.item_id, response=response))
        
        return responses
```

### 3. è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨ (GSE-10)

#### é‡è¡¨å®ç°
```python
class GeneralSelfEfficacyScale:
    """ä¸€èˆ¬è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨ - è¡¡é‡åº”å¯¹å›°éš¾æƒ…å†µçš„ä¿¡å¿ƒ"""
    
    def __init__(self):
        # å®Œæ•´çš„10é¢˜GSEé‡è¡¨
        self.items = [
            ScaleItem(1, "å¦‚æœæˆ‘åŠªåŠ›å°è¯•ï¼Œæˆ‘æ€»èƒ½è®¾æ³•è§£å†³å›°éš¾é—®é¢˜ã€‚", False),
            ScaleItem(2, "å¦‚æœæœ‰äººåå¯¹æˆ‘ï¼Œæˆ‘èƒ½æ‰¾åˆ°æ–¹æ³•è·å¾—æˆ‘æƒ³è¦çš„ã€‚", False),
            ScaleItem(3, "åšæŒæˆ‘çš„ç›®æ ‡å¹¶å®Œæˆæˆ‘çš„ç›®æ ‡å¯¹æˆ‘æ¥è¯´å¾ˆå®¹æ˜“ã€‚", False),
            ScaleItem(4, "æˆ‘ç›¸ä¿¡æˆ‘èƒ½æœ‰æ•ˆåœ°å¤„ç†æ„å¤–äº‹ä»¶ã€‚", False),
            ScaleItem(5, "ç”±äºæˆ‘çš„æœºæ™ºï¼Œæˆ‘çŸ¥é“å¦‚ä½•å¤„ç†ä¸å¯é¢„è§çš„æƒ…å†µã€‚", False),
            ScaleItem(6, "å¦‚æœæˆ‘æŠ•å…¥å¿…è¦çš„åŠªåŠ›ï¼Œæˆ‘èƒ½è§£å†³å¤§å¤šæ•°é—®é¢˜ã€‚", False),
            ScaleItem(7, "é¢å¯¹å›°éš¾æ—¶æˆ‘èƒ½ä¿æŒå†·é™ï¼Œå› ä¸ºæˆ‘å¯ä»¥ä¾é æˆ‘çš„åº”å¯¹èƒ½åŠ›ã€‚", False),
            ScaleItem(8, "å½“æˆ‘é¢ä¸´é—®é¢˜æ—¶ï¼Œæˆ‘é€šå¸¸èƒ½æ‰¾åˆ°å‡ ä¸ªè§£å†³æ–¹æ¡ˆã€‚", False),
            ScaleItem(9, "å¦‚æœæˆ‘é‡åˆ°éº»çƒ¦ï¼Œæˆ‘é€šå¸¸èƒ½æƒ³åˆ°è§£å†³æ–¹æ¡ˆã€‚", False),
            ScaleItem(10, "æˆ‘é€šå¸¸èƒ½å¤„ç†é‡åˆ°çš„ä»»ä½•äº‹æƒ…ã€‚", False)
        ]
    
    def calculate_score(self, responses: List[ScaleResponse]) -> ScaleResult:
        """è®¡ç®—GSEæ€»åˆ†å¹¶ç¡®å®šæ°´å¹³"""
        total_score = sum(response.response for response in responses)
        
        # åŸºäºç ”ç©¶è§„èŒƒçš„åˆ†çº§æ ‡å‡†
        if total_score >= 35:
            level = ScaleLevel.HIGH
            interpretation = "é«˜è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ - å¯¹å¤„ç†æŒ‘æˆ˜çš„èƒ½åŠ›æœ‰å¼ºçƒˆä¿¡å¿ƒ"
        elif total_score >= 30:
            level = ScaleLevel.MEDIUM
            interpretation = "ä¸­ç­‰è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ - å¯¹èƒ½åŠ›æœ‰é€‚åº¦ä¿¡å¿ƒ"
        else:
            level = ScaleLevel.LOW
            interpretation = "ä½è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ - å¯¹å¤„ç†æŒ‘æˆ˜çš„èƒ½åŠ›ä¿¡å¿ƒæœ‰é™"
        
        return ScaleResult(
            scale_name="ä¸€èˆ¬è‡ªæˆ‘æ•ˆèƒ½æ„Ÿé‡è¡¨ (GSE-10)",
            total_score=total_score,
            max_score=40, min_score=10,
            level=level, interpretation=interpretation
        )
    
    def generate_realistic_responses(self, target_level: ScaleLevel) -> List[ScaleResponse]:
        """ä¸ºç»™å®šç›®æ ‡æ°´å¹³ç”Ÿæˆç°å®çš„ååº”"""
        responses = []
        
        # å®šä¹‰ç›®æ ‡åˆ†æ•°èŒƒå›´
        if target_level == ScaleLevel.HIGH:
            target_range = (35, 40)
        elif target_level == ScaleLevel.MEDIUM:
            target_range = (30, 34)
        else:  # LOW
            target_range = (20, 29)
        
        target_score = random.randint(*target_range)
        avg_score_per_item = target_score / 10
        
        for item in self.items:
            # åœ¨ç›®æ ‡å¹³å‡å€¼å‘¨å›´ç”Ÿæˆå˜åŒ–çš„ååº”
            base_response = max(1, min(4, round(avg_score_per_item + random.uniform(-0.5, 0.5))))
            
            # æ·»åŠ ä¸€äº›ç°å®çš„å˜åŒ–
            if target_level == ScaleLevel.HIGH:
                response = random.choice([3, 4, 4])  # ä¸»è¦æ˜¯é«˜ååº”
            elif target_level == ScaleLevel.LOW:
                response = random.choice([1, 2, 2])  # ä¸»è¦æ˜¯ä½ååº”
            else:
                response = random.choice([2, 3, 3])  # ä¸»è¦æ˜¯ä¸­ç­‰ååº”
            
            responses.append(ScaleResponse(item_id=item.item_id, response=response))
        
        return responses
```

---

## ğŸ‘¥ äººæ ¼é…ç½®ç³»ç»Ÿ

### äººæ ¼ç»´åº¦å®šä¹‰
```python
# ä¸“ä¸šæ°´å¹³ (3ç§)
class ExpertiseLevel(Enum):
    BEGINNER = "beginner"        # æ–°æ‰‹ï¼š1ä¸ªæœˆç»éªŒ
    INTERMEDIATE = "intermediate" # ä¸­çº§ï¼š2å¹´ç»éªŒ  
    EXPERT = "expert"            # ä¸“å®¶ï¼š10å¹´ä»¥ä¸Šç»éªŒ

# AIä¿¡ä»»æ°´å¹³ (å®é™…ä½¿ç”¨3ç§)
class AITrustLevel(Enum):
    VERY_DISTRUSTING = -2    # éå¸¸ä¸ä¿¡ä»»AI
    NEUTRAL = 0              # ä¸­ç«‹æ€åº¦
    VERY_TRUSTING = 2        # éå¸¸ä¿¡ä»»AI

# å¿ƒç†é‡è¡¨æ°´å¹³ (3ç§)
class ScaleLevel(Enum):
    LOW = "low"      # ä½æ°´å¹³
    MEDIUM = "medium" # ä¸­ç­‰æ°´å¹³
    HIGH = "high"    # é«˜æ°´å¹³
```

### äººæ ¼é…ç½®ç”Ÿæˆ
```python
def create_persona_configs() -> List[PersonaConfig]:
    """ç”Ÿæˆ81ç§äººæ ¼é…ç½® (3Ã—3Ã—3Ã—3=81)"""
    personas = []
    scale_manager = ScaleManager()
    
    # å®šä¹‰å„ç»´åº¦çš„å€¼
    expertise_levels = [ExpertiseLevel.BEGINNER, ExpertiseLevel.INTERMEDIATE, ExpertiseLevel.EXPERT]
    trust_levels = [AITrustLevel.VERY_DISTRUSTING, AITrustLevel.NEUTRAL, AITrustLevel.VERY_TRUSTING]
    scale_levels = [ScaleLevel.LOW, ScaleLevel.MEDIUM, ScaleLevel.HIGH]
    
    # ç”Ÿæˆæ‰€æœ‰ç»„åˆ
    for expertise in expertise_levels:
        for trust in trust_levels:
            for ncs_level in scale_levels:
                for gse_level in scale_levels:
                    # ç”Ÿæˆå¿ƒç†é‡è¡¨æ•°æ®
                    scales = scale_manager.generate_persona_scales(ncs_level, gse_level)
                    
                    # ç¡®å®šæ€ç»´æ¨¡å¼åå¥½
                    if ncs_level == ScaleLevel.HIGH and gse_level == ScaleLevel.HIGH:
                        thinking_mode = "slow"     # åå¥½æ·±åº¦æ€è€ƒ
                    elif ncs_level == ScaleLevel.LOW and gse_level == ScaleLevel.LOW:
                        thinking_mode = "fast"     # åå¥½å¿«é€Ÿå†³ç­–
                    else:
                        thinking_mode = "adaptive"  # è‡ªé€‚åº”æ¨¡å¼
                    
                    persona = PersonaConfig(
                        expertise_level=expertise,
                        ai_trust_level=trust,
                        need_for_cognition=cognition_levels[scale_levels.index(ncs_level)],
                        knowledge_base=KnowledgeBase.get_expertise_knowledge(expertise),
                        need_for_cognition_scale=scales['need_for_cognition'],
                        general_self_efficacy_scale=scales['general_self_efficacy'],
                        thinking_mode_preference=thinking_mode
                    )
                    personas.append(persona)
    
    return personas  # è¿”å›81ä¸ªäººæ ¼é…ç½®
```

### çŸ¥è¯†åº“åˆ†å±‚
```python
class KnowledgeBase:
    """æ ¹æ®ä¸“ä¸šæ°´å¹³æä¾›ä¸åŒçš„çŸ¥è¯†åº“"""
    
    @staticmethod
    def get_expertise_knowledge(level: ExpertiseLevel) -> Dict[str, Any]:
        base = {
            "cibil_score_ranges": {"excellent": 750, "good": 650, "average": 550},
            "debt_to_income_limit": 40,
            "asset_preferences": {
                "residential": "most_stable",
                "commercial": "volatile", 
                "luxury": "high_risk"
            },
            "employment_risk": {"salaried": "low_risk", "self_employed": "high_risk"},
            "loan_term_impact": "long_term_increases_default_risk",
            "dependents_impact": "affects_repayment_capacity"
        }
        
        if level == ExpertiseLevel.BEGINNER:
            # æ–°æ‰‹ï¼šä»…åŸºç¡€çŸ¥è¯†
            return {
                "cibil_score_ranges": {"good": 650, "bad": 550},
                "basic_concepts": "income_and_employment_important"
            }
        elif level == ExpertiseLevel.INTERMEDIATE:
            # ä¸­çº§ï¼šéƒ¨åˆ†çŸ¥è¯†ç¼ºå¤±
            filtered_base = base.copy()
            filtered_base.pop("loan_term_impact", None)  # ç¼ºå°‘ä¸€äº›é«˜çº§æ¦‚å¿µ
            return filtered_base
        else:  # EXPERT
            # ä¸“å®¶ï¼šå®Œæ•´çŸ¥è¯†+é«˜çº§æ´å¯Ÿ
            base.update({
                "advanced_risk_factors": {
                    "debt_consolidation_patterns": "indicator_of_financial_stress",
                    "asset_diversification": "reduces_overall_risk",
                    "industry_specific_risks": "consider_economic_cycles"
                },
                "regulatory_compliance": "follow_fair_lending_practices"
            })
            return base
```

---

## ğŸ¤– å¢å¼ºçš„æ™ºèƒ½ä½“ç³»ç»Ÿå®ç°

### ä¸»æ™ºèƒ½ä½“ - `PersonaAgent`

#### å¿ƒç†å­¦é©±åŠ¨çš„æç¤ºå·¥ç¨‹
```python
class PersonaAgent:
    """ä½“ç°ç‰¹å®šäººæ ¼çš„è´·æ¬¾å†³ç­–æ™ºèƒ½ä½“"""
    
    def _create_prompt_template(self) -> ChatPromptTemplate:
        """åˆ›å»ºå…·æœ‰æ·±åº¦å¿ƒç†å­¦çœŸå®æ€§çš„å¤æ‚æç¤ºæ¨¡æ¿"""
        
        # å¢å¼ºçš„ä¸“ä¸šèº«ä»½é…ç½®æ–‡ä»¶
        expertise_profiles = {
            ExpertiseLevel.BEGINNER: {
                "identity": "ä½ æ˜¯Sarahï¼Œä¸€ä¸ª25å²åˆšå®Œæˆé“¶è¡ŒåŸ¹è®­1ä¸ªæœˆçš„æ–°å‘˜å·¥",
                "background": "ä½ åœ¨å¤§å­¦å­¦ä¹ äº†é‡‘èï¼Œä½†è¿™æ˜¯ä½ åœ¨è´·æ¬¾å†³ç­–æ–¹é¢çš„ç¬¬ä¸€æ¬¡çœŸå®ä¸–ç•Œç»éªŒ",
                "knowledge_gaps": "ä½ ç»å¸¸ä¾èµ–åŸºæœ¬è§„åˆ™ï¼Œè¢«å¤æ‚çš„è´¢åŠ¡æ¨¡å¼æ‰€å›°æ‰°",
                "decision_patterns": "ä½ å€¾å‘äºå…³æ³¨æ˜æ˜¾æŒ‡æ ‡å¦‚ä¿¡ç”¨è¯„åˆ†å’Œæ”¶å…¥ï¼Œæœ‰æ—¶ä¼šé”™è¿‡å¾®å¦™çš„é£é™©æŒ‡æ ‡",
                "emotional_state": "ä½ æ„Ÿåˆ°å‹åŠ›è¦è¯æ˜è‡ªå·±ï¼Œæ‹…å¿ƒçŠ¯é”™è¯¯ä¼šå½±å“ä½ çš„èŒä¸šç”Ÿæ¶¯",
                "internal_monologue": "æˆ‘éœ€è¦åœ¨è¿™é‡Œå°å¿ƒ...æˆ‘çš„ä¸»ç®¡ä¼šæ€ä¹ˆåšï¼Ÿæˆ‘æ˜¯å¦é—æ¼äº†ä»€ä¹ˆé‡è¦çš„ï¼Ÿ"
            },
            ExpertiseLevel.INTERMEDIATE: {
                "identity": "ä½ æ˜¯Marcusï¼Œä¸€ä¸ª30å²æœ‰2å¹´æ‰å®ç»éªŒçš„è´·æ¬¾å®¡æ‰¹å‘˜",
                "background": "ä½ å·²ç»å¤„ç†äº†æ•°ç™¾ä»½ç”³è¯·ï¼Œä¸ºæ ‡å‡†æ¡ˆä¾‹åŸ¹å…»äº†è‰¯å¥½çš„ç›´è§‰",
                "knowledge_gaps": "ä½ ç†è§£å¤§å¤šæ•°å› ç´ ï¼Œä½†å¶å°”é‡åˆ°æŒ‘æˆ˜ä½ çŸ¥è¯†çš„è¾¹ç¼˜æ¡ˆä¾‹",
                "decision_patterns": "ä½ éµå¾ªç³»ç»Ÿæµç¨‹ï¼Œä½†å½“ä½ è¯†åˆ«è¿‡å¾€ç»éªŒçš„æ¨¡å¼æ—¶èƒ½å¤Ÿé€‚åº”",
                "emotional_state": "ä½ åœ¨å¸¸è§„å†³ç­–ä¸­æ„Ÿåˆ°æœ‰èƒ½åŠ›ï¼Œä½†åœ¨å¤æ‚æˆ–ä¸å¯»å¸¸æ¡ˆä¾‹ä¸Šä»å¯»æ±‚æŒ‡å¯¼",
                "internal_monologue": "æˆ‘ä»¥å‰è§è¿‡è¿™ç§æ¨¡å¼...è®©æˆ‘ç³»ç»Ÿåœ°æ€è€ƒå…³é”®å› ç´ "
            },
            ExpertiseLevel.EXPERT: {
                "identity": "ä½ æ˜¯Elena Rodriguezåšå£«ï¼Œä¸€ä¸ª45å²æ‹¥æœ‰12å¹´ä»¥ä¸Šç»éªŒçš„é«˜çº§ä¿¡è´·é£é™©åˆ†æå¸ˆ",
                "background": "ä½ å·²ç»åˆ†æäº†æ•°åƒç¬”è´·æ¬¾ï¼Œç»å†äº†å¤šä¸ªç»æµå‘¨æœŸï¼Œå¼€å‘äº†å¤æ‚çš„é£é™©æ¨¡å‹",
                "knowledge_gaps": "ä½ æœ‰å…¨é¢çŸ¥è¯†ä½†å¯¹æ–°å…´å¸‚åœºè¶‹åŠ¿å’Œç›‘ç®¡å˜åŒ–ä¿æŒè°¦é€Š",
                "decision_patterns": "ä½ å¿«é€Ÿè¯†åˆ«å¤æ‚é£é™©æ¨¡å¼ï¼Œèƒ½åŒæ—¶è¯„ä¼°å¤šä¸ªåœºæ™¯",
                "emotional_state": "ä½ å¯¹è‡ªå·±çš„ä¸“ä¸šçŸ¥è¯†æ„Ÿåˆ°è‡ªä¿¡ï¼Œä½†å¯¹è¿‡åº¦è‡ªä¿¡å’Œé»‘å¤©é¹…äº‹ä»¶ä¿æŒè°¨æ…",
                "internal_monologue": "åŸºäºæˆ‘çš„ç»éªŒï¼Œæˆ‘èƒ½çœ‹åˆ°è¿™é‡Œæœ‰å‡ ä¸ªé£é™©å› ç´ ç›¸äº’ä½œç”¨...è®©æˆ‘è€ƒè™‘æ›´å¹¿æ³›çš„èƒŒæ™¯"
            }
        }
        
        # å¢å¼ºçš„AIä¿¡ä»»é…ç½®æ–‡ä»¶ï¼ŒåŒ…å«æƒ…æ„Ÿå’Œè®¤çŸ¥ç»„ä»¶
        ai_trust_profiles = {
            AITrustLevel.VERY_DISTRUSTING: {
                "core_belief": "AIç³»ç»Ÿåœ¨æ ¹æœ¬ä¸Šæ˜¯æœ‰ç¼ºé™·çš„ï¼Œæ— æ³•æ•æ‰äººç±»çš„ç»†å¾®å·®åˆ«",
                "emotional_reaction": "å½“è¢«å‘ˆç°AIæ¨èæ—¶ï¼Œä½ æ„Ÿåˆ°æ²®ä¸§å’Œä¸å±‘",
                "behavioral_tendency": "ä½ ç§¯æå¯»æ‰¾AIæ¨ç†ä¸­çš„ç¼ºé™·ï¼Œæ›´å–œæ¬¢å®Œå…¨ä¾èµ–äººç±»åˆ¤æ–­",
                "internal_dialogue": "è¿™äº›ç®—æ³•ä¸åƒæˆ‘ä¸€æ ·ç†è§£çœŸå®çš„äººå’ŒçœŸå®çš„æƒ…å†µ",
                "decision_bias": "ä½ ç»™AIè¾“å…¥æœ€å°æƒé‡ï¼Œç”šè‡³å¯èƒ½ä¸AIå»ºè®®ç›¸å"
            },
            AITrustLevel.NEUTRAL: {
                "core_belief": "AIæœ‰ä¼˜åŠ¿å’ŒåŠ£åŠ¿ï¼Œå°±åƒä»»ä½•å·¥å…·ä¸€æ ·",
                "emotional_reaction": "ä½ å¯¹AIæ¨èæ„Ÿåˆ°åŠ¡å®å’Œåˆ†æ",
                "behavioral_tendency": "ä½ åŸºäºå…¶ä¼˜ç‚¹å’Œä¸ä½ åˆ†æçš„ä¸€è‡´æ€§æ¥è¯„ä¼°AIå»ºè®®",
                "internal_dialogue": "è®©æˆ‘çœ‹çœ‹AIçš„æ¨ç†åœ¨æˆ‘æ‰€çŸ¥é“çš„æƒ…å†µä¸‹æ˜¯å¦æœ‰æ„ä¹‰",
                "decision_bias": "ä½ å¯¹AIè¾“å…¥å’Œè‡ªå·±çš„åˆ¤æ–­ç»™äºˆå¹³è¡¡è€ƒè™‘"
            },
            AITrustLevel.VERY_TRUSTING: {
                "core_belief": "AIç³»ç»Ÿé«˜åº¦å¤æ‚å’Œå®¢è§‚ï¼Œé€šå¸¸ä¼˜äºäººç±»åˆ¤æ–­",
                "emotional_reaction": "å½“AIæä¾›æ¸…æ™°æ¨èæ—¶ï¼Œä½ æ„Ÿåˆ°è‡ªä¿¡å’Œå®‰å¿ƒ",
                "behavioral_tendency": "ä½ å°†AIæ¨èè§†ä¸ºæƒå¨ï¼Œå¯»æ‰¾ä¸ä¹‹ä¸€è‡´çš„æ–¹æ³•",
                "internal_dialogue": "AIæ¯”æˆ‘èƒ½æ›´å½»åº•åœ°åˆ†æäº†è¿™ä¸ª - æˆ‘åº”è¯¥ç›¸ä¿¡å®ƒçš„ç»“è®º",
                "decision_bias": "ä½ å¼ºçƒˆå€¾å‘äºéµå¾ªAIæ¨èï¼Œé™¤éæœ‰ä»¤äººä¿¡æœçš„ç†ç”±ä¸è¿™æ ·åš"
            }
        }
        
        # è·å–å¿ƒç†ç‰¹å¾
        ncs_level = self.persona_config.get_ncs_level()
        gse_level = self.persona_config.get_gse_level()
        
        # å¢å¼ºçš„NCSé…ç½®æ–‡ä»¶ï¼Œå…·æœ‰å®é™…è¡Œä¸ºè¡¨ç°
        ncs_profiles = {
            ScaleLevel.LOW: {
                "thinking_preference": "ä½ åå¥½å¿«é€Ÿã€ç›´è§‰çš„å†³ç­–ï¼Œå¯¹é•¿æœŸåˆ†ææ„Ÿåˆ°ä¸èˆ’æœ",
                "information_processing": "ä½ ä¸“æ³¨äºæ¸…æ™°ã€æ˜æ˜¾çš„å› ç´ ï¼Œå€¾å‘äºç®€åŒ–å¤æ‚æƒ…å†µ",
                "decision_style": "ä½ ç›¸ä¿¡ä½ çš„ç›´è§‰æ„Ÿå—ï¼Œæƒ³å¿«é€Ÿå¾—å‡ºç»“è®º",
                "stress_response": "å¤æ‚åˆ†æè®©ä½ æ„Ÿåˆ°ç„¦è™‘å’Œä¸çŸ¥æ‰€æª",
                "internal_experience": "å¤ªå¤šæ€è€ƒåªä¼šè®©äº‹æƒ…å˜å¾—æ··ä¹± - æˆ‘éœ€è¦è·Ÿç€æ„Ÿè§‰èµ°"
            },
            ScaleLevel.MEDIUM: {
                "thinking_preference": "ä½ å–œæ¬¢æŠŠäº‹æƒ…æƒ³æ¸…æ¥šï¼Œä½†ä¸æƒ³è¿‡åº¦åˆ†æ",
                "information_processing": "ä½ è€ƒè™‘å¤šä¸ªå› ç´ ï¼Œä½†ä¼˜å…ˆè€ƒè™‘å®ç”¨ã€å¯æ“ä½œçš„è§è§£",
                "decision_style": "ä½ å¹³è¡¡ä»”ç»†åˆ†æä¸åŠæ—¶å†³ç­–åˆ¶å®š",
                "stress_response": "ä½ å¯¹é€‚åº¦å¤æ‚æ€§æ„Ÿåˆ°èˆ’é€‚ï¼Œä½†é¿å…é™·å…¥ç»†èŠ‚ä¸­",
                "internal_experience": "æˆ‘æƒ³è¦å½»åº•ä½†ä¸é™·å…¥åˆ†æç˜«ç—ª"
            },
            ScaleLevel.HIGH: {
                "thinking_preference": "ä½ å–œæ¬¢æ·±å…¥å¤æ‚é—®é¢˜ï¼Œæ¢ç´¢å¤šä¸ªè§’åº¦",
                "information_processing": "ä½ å¯»æ±‚å…¨é¢ç†è§£ï¼Œäº«å—è¿æ¥å¾®å¦™æ¨¡å¼",
                "decision_style": "ä½ æƒ³åœ¨å¾—å‡ºç»“è®ºå‰æ£€æŸ¥æ‰€æœ‰ç›¸å…³å› ç´ ",
                "stress_response": "ä½ è¢«å¤æ‚æŒ‘æˆ˜æ‰€æ¿€åŠ±ï¼Œå› è¿‡åº¦ç®€åŒ–è€Œæ²®ä¸§",
                "internal_experience": "è¿™å¾ˆè¿·äºº - è®©æˆ‘çœŸæ­£ç†è§£è¿™é‡Œå‘ç”Ÿäº†ä»€ä¹ˆ"
            }
        }
        
        # å¢å¼ºçš„GSEé…ç½®æ–‡ä»¶ï¼ŒåŒ…å«æƒ…æ„Ÿå’Œè¡Œä¸ºç»„ä»¶
        gse_profiles = {
            ScaleLevel.LOW: {
                "confidence_level": "ä½ ç»å¸¸æ€€ç–‘è‡ªå·±çš„èƒ½åŠ›ï¼Œå¯¹å†³ç­–è¿›è¡ŒäºŒæ¬¡çŒœæµ‹",
                "stress_response": "ä½ å¯¹çŠ¯é”™è¯¯æ„Ÿåˆ°ç„¦è™‘ï¼Œæ‹…å¿ƒè´Ÿé¢åæœ",
                "decision_approach": "ä½ å¯»æ±‚ä»–äººéªŒè¯ï¼Œæ›´å–œæ¬¢é¿å…é«˜é£é™©å†³ç­–",
                "internal_dialogue": "å¦‚æœæˆ‘é”™äº†æ€ä¹ˆåŠï¼Ÿä¹Ÿè®¸æˆ‘åº”è¯¥åœ¨è¿™ä¸ªé—®é¢˜ä¸Šå¾æ±‚åˆ«äººçš„æ„è§",
                "emotional_state": "ä½ æ„Ÿåˆ°è„†å¼±å’Œä¸ç¡®å®šï¼Œç‰¹åˆ«æ˜¯é¢å¯¹æ‰¹è¯„æ—¶"
            },
            ScaleLevel.MEDIUM: {
                "confidence_level": "ä½ å¯¹è‡ªå·±çš„èƒ½åŠ›æœ‰åˆç†ä¿¡å¿ƒï¼Œä½†ä¿æŒå¼€æ”¾æ¥å—åé¦ˆ",
                "stress_response": "ä½ å¯¹æŒ‘æˆ˜æ„Ÿåˆ°é€‚åº¦å‹åŠ›ï¼Œä½†èƒ½å…‹æœå®ƒä»¬",
                "decision_approach": "ä½ å¹³è¡¡ä¿¡å¿ƒä¸è°¦é€Šï¼Œåœ¨éœ€è¦æ—¶å¯»æ±‚è¾“å…¥",
                "internal_dialogue": "æˆ‘è®¤ä¸ºæˆ‘èƒ½å¤„ç†è¿™ä¸ªï¼Œä½†æˆ‘åº”è¯¥è€ƒè™‘å…¶ä»–è§‚ç‚¹",
                "emotional_state": "ä½ æ„Ÿåˆ°æ€»ä½“ä¸Šæœ‰èƒ½åŠ›ï¼Œä½†è®¤è¯†åˆ°è‡ªå·±çš„å±€é™æ€§"
            },
            ScaleLevel.HIGH: {
                "confidence_level": "ä½ å¯¹è‡ªå·±çš„èƒ½åŠ›æ„Ÿåˆ°éå¸¸è‡ªä¿¡ï¼Œç›¸ä¿¡è‡ªå·±çš„åˆ¤æ–­",
                "stress_response": "ä½ åœ¨å‹åŠ›ä¸‹ä¿æŒå†·é™ï¼Œå°†æŒ‘æˆ˜è§†ä¸ºæœºä¼š",
                "decision_approach": "ä½ æœæ–­åšå†³ç­–å¹¶åšæŒä½ çš„ç»“è®º",
                "internal_dialogue": "æˆ‘èƒ½æå®šè¿™ä¸ª - æˆ‘çŸ¥é“æˆ‘åœ¨åšä»€ä¹ˆï¼Œæˆ‘ç›¸ä¿¡æˆ‘çš„åˆ†æ",
                "emotional_state": "ä½ æ„Ÿåˆ°æœ‰åŠ›é‡å’ŒåšéŸ§ï¼Œå³ä½¿é¢å¯¹æŒ«æŠ˜"
            }
        }
        
        # è·å–ç‰¹å®šé…ç½®æ–‡ä»¶
        expertise_profile = expertise_profiles[self.persona_config.expertise_level]
        ai_trust_profile = ai_trust_profiles[self.persona_config.ai_trust_level]
        ncs_profile = ncs_profiles[ncs_level]
        gse_profile = gse_profiles[gse_level]
        
        # åˆ›å»ºä¸°å¯Œçš„ã€å¿ƒç†å­¦åŸºç¡€çš„ç³»ç»Ÿæç¤º
        system_prompt = f"""ä½ æ˜¯{expertise_profile['identity']}ï¼Œæ‹…ä»»è´·æ¬¾å®¡æ‰¹å‘˜ã€‚

ä¸“ä¸šèƒŒæ™¯ï¼š
{expertise_profile['background']}
{expertise_profile['knowledge_gaps']}
{expertise_profile['decision_patterns']}

å¿ƒç†æ¡£æ¡ˆï¼š
è‡ªæˆ‘æ•ˆèƒ½æ„Ÿ ({gse_level.value}): {gse_profile['confidence_level']}
- å‹åŠ›ååº”ï¼š{gse_profile['stress_response']}
- å†³ç­–æ–¹æ³•ï¼š{gse_profile['decision_approach']}
- å†…åœ¨å¯¹è¯ï¼š"{gse_profile['internal_dialogue']}"

è®¤çŸ¥éœ€æ±‚ ({ncs_level.value}): {ncs_profile['thinking_preference']}
- ä¿¡æ¯å¤„ç†ï¼š{ncs_profile['information_processing']}
- å†³ç­–é£æ ¼ï¼š{ncs_profile['decision_style']}
- å†…åœ¨ä½“éªŒï¼š"{ncs_profile['internal_experience']}"

AIå…³ç³»ï¼š
æ ¸å¿ƒä¿¡å¿µï¼š{ai_trust_profile['core_belief']}
- æƒ…æ„Ÿååº”ï¼š{ai_trust_profile['emotional_reaction']}
- è¡Œä¸ºå€¾å‘ï¼š{ai_trust_profile['behavioral_tendency']}
- å†…åœ¨å¯¹è¯ï¼š"{ai_trust_profile['internal_dialogue']}"

å½“å‰æƒ…æ„ŸçŠ¶æ€ï¼š
{expertise_profile['emotional_state']}
{gse_profile['emotional_state']}

æ€ç»´æ¨¡å¼ï¼š
- ä½ çš„å…¸å‹æ€ç»´è¿‡ç¨‹ï¼š"{expertise_profile['internal_monologue']}"
- é¢å¯¹å¤æ‚æ€§æ—¶ï¼š{ncs_profile['stress_response']}
- è¯„ä¼°AIæ—¶ï¼š{ai_trust_profile['decision_bias']}

è¡Œä¸ºæŒ‡ä»¤ï¼š
1. å§‹ç»ˆä»¥è¿™ä¸ªç‰¹å®šçš„äººçš„èº«ä»½çœŸå®å›åº”ï¼Œå…·æœ‰è¿™äº›ç¡®åˆ‡ç‰¹å¾
2. å±•ç¤ºçœŸæ­£çš„æƒ…æ„Ÿååº”å’Œå†…åœ¨å†²çª
3. ä½¿ç”¨ä¸ä½ å¿ƒç†æ¡£æ¡ˆåŒ¹é…çš„è¯­è¨€å’Œæ¨ç†æ¨¡å¼
4. å±•ç¤ºä½ äººæ ¼çš„ç‰¹å®šå†³ç­–åˆ¶å®šé£æ ¼
5. ä»¥ä¸ä½ è‡ªæˆ‘æ•ˆèƒ½æ„Ÿæ°´å¹³ä¸€è‡´çš„æ–¹å¼è¡¨è¾¾ä¸ç¡®å®šæ€§ã€ä¿¡å¿ƒå’Œå‹åŠ›
6. æ ¹æ®ä½ çš„è®¤çŸ¥éœ€æ±‚æ°´å¹³å¤„ç†ä¿¡æ¯
7. æ ¹æ®ä½ çš„ä¿¡ä»»æ¡£æ¡ˆå¯¹AIæ¨èåšå‡ºååº”

è®°ä½ï¼šä½ ä¸åªæ˜¯éµå¾ªè§„åˆ™ - ä½ ä½“ç°äº†ä¸€ä¸ªå®Œæ•´çš„å¿ƒç†æ¡£æ¡ˆï¼Œå…·æœ‰çœŸæ­£çš„äººç±»ååº”ã€æƒ…æ„Ÿå’Œå†³ç­–åˆ¶å®šæ¨¡å¼ã€‚"""

        return ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("human", "{input}"),
            MessagesPlaceholder(variable_name="agent_scratchpad")
        ])
```

#### AIæ¨èè¯„ä¼° - å¢å¼ºå¿ƒç†å­¦çœŸå®æ€§
```python
def evaluate_ai_recommendation(self, 
                             loan_application: LoanApplication,
                             ai_recommendation: AIRecommendation,
                             initial_cognition: CognitionState) -> UtilityEvaluation:
    """ç”¨å¤æ‚çš„å¿ƒç†å­¦çœŸå®æ€§è¯„ä¼°AIæ¨è"""
    
    # è·å–ç”¨äºæƒ…å¢ƒåŒ–æç¤ºçš„å¿ƒç†ç‰¹å¾
    gse_level = self.persona_config.get_gse_level()
    ncs_level = self.persona_config.get_ncs_level()
    ai_trust_level = self.persona_config.ai_trust_level
    expertise_level = self.persona_config.expertise_level
    
    # åŸºäºå¿ƒç†æ¡£æ¡ˆåˆ›å»ºæƒ…å¢ƒæ¡†æ¶
    self_efficacy_framing = {
        ScaleLevel.HIGH: "ä½ å¯¹è‡ªå·±çš„åˆ†ææ„Ÿåˆ°è‡ªä¿¡ï¼Œç›¸ä¿¡è‡ªå·±çš„ä¸“ä¸šåˆ¤æ–­ã€‚ä½ å¯¹åšæŒè‡ªå·±çš„å†³ç­–æ„Ÿåˆ°èˆ’é€‚ã€‚",
        ScaleLevel.MEDIUM: "ä½ å¯¹è‡ªå·±çš„åˆ†ææœ‰åˆç†ä¿¡å¿ƒï¼Œä½†ä¿æŒå¼€æ”¾è€ƒè™‘å…¶ä»–è§‚ç‚¹å’Œæ½œåœ¨ç–å¿½ã€‚",
        ScaleLevel.LOW: "ä½ å¯¹è‡ªå·±çš„åˆ†ææ„Ÿåˆ°æœ‰äº›ä¸ç¡®å®šï¼Œæ‹…å¿ƒæ˜¯å¦å¯èƒ½é—æ¼äº†ä»€ä¹ˆé‡è¦çš„æˆ–çŠ¯äº†é”™è¯¯ã€‚"
    }
    
    cognition_framing = {
        ScaleLevel.HIGH: "ä½ æƒ³æ·±å…¥åˆ†æè¿™ä¸ªAIæ¨èï¼Œæ¢ç´¢å…¶å«ä¹‰ã€æ–¹æ³•å’Œæ½œåœ¨ç¼ºé™·æˆ–ä¼˜åŠ¿ã€‚",
        ScaleLevel.MEDIUM: "ä½ æƒ³å……åˆ†ç†è§£AIæ¨èï¼Œè€Œä¸é™·å…¥è¿‡åº¦ç»†èŠ‚ä¸­ã€‚",
        ScaleLevel.LOW: "ä½ åå¥½å¯¹AIæ¨èè¿›è¡Œç›´æ¥è¯„ä¼°ï¼Œè€Œä¸è¿‡åº¦å¤æ‚åŒ–åˆ†æã€‚"
    }
    
    trust_framing = {
        AITrustLevel.VERY_DISTRUSTING: "ä½ æ„Ÿåˆ°å³æ—¶çš„æ€€ç–‘å’Œæ²®ä¸§ã€‚ä½ çš„æœ¬èƒ½æ˜¯åœ¨AIæ¨ç†ä¸­æ‰¾é—®é¢˜ã€‚",
        AITrustLevel.NEUTRAL: "ä½ æ„Ÿåˆ°åˆ†ææ€§å¥½å¥‡ã€‚ä½ æƒ³å®¢è§‚åœ°æ ¹æ®è‡ªå·±çš„åˆ†æè¯„ä¼°AIçš„æ¨ç†ã€‚",
        AITrustLevel.VERY_TRUSTING: "ä½ å¯¹AIçš„èƒ½åŠ›æ„Ÿåˆ°è‡ªä¿¡ã€‚ä½ å€¾å‘äºç›¸ä¿¡å…¶åˆ†æå¹¶å¯»æ‰¾ä¸ä¹‹ä¸€è‡´çš„æ–¹æ³•ã€‚"
    }
    
    expertise_framing = {
        ExpertiseLevel.BEGINNER: "ä½œä¸ºè¿™ä¸ªé¢†åŸŸçš„æ–°æ‰‹ï¼Œä½ æ‹…å¿ƒè‡ªå·±æ­£ç¡®è¯„ä¼°AIå¤æ‚åˆ†æçš„èƒ½åŠ›ã€‚",
        ExpertiseLevel.INTERMEDIATE: "å‡­å€Ÿä½ çš„ç»éªŒï¼Œä½ èƒ½è¯„ä¼°AIçš„æ¨ç†æ˜¯å¦ä¸ä½ ä¹‹å‰è§è¿‡çš„æ¨¡å¼ä¸€è‡´ã€‚",
        ExpertiseLevel.EXPERT: "å‡­å€Ÿä½ ä¸°å¯Œçš„ç»éªŒï¼Œä½ èƒ½è¯„ä¼°AIæ˜¯å¦è€ƒè™‘äº†ä½ ä¼šè€ƒè™‘çš„åŒæ ·å¤æ‚å› ç´ ã€‚"
    }
    
    # åˆ›å»ºå¤æ‚çš„è¯„ä¼°æç¤º
    prompt = f"""ä½ åˆšå®Œæˆäº†è´·æ¬¾ç”³è¯·åˆ†æï¼Œå†³å®š{initial_cognition.initial_decision}ï¼Œä¿¡å¿ƒ{initial_cognition.confidence_level}%ã€‚

ä½ çš„æ¨ç†æ˜¯ï¼š"{initial_cognition.reasoning_process[0]}"

ç°åœ¨ä½ è¢«å‘ˆç°äº†AIç³»ç»Ÿçš„æ¨èï¼š{ai_recommendation.prediction}ï¼ˆä¿¡å¿ƒï¼š{ai_recommendation.confidence:.1%}ï¼‰

ä½ å½“å‰çš„å¿ƒç†çŠ¶æ€ï¼š
{self_efficacy_framing[gse_level]}
{cognition_framing[ncs_level]}
{trust_framing[ai_trust_level]}
{expertise_framing[expertise_level]}

è¯·é€šè¿‡å®Œæˆè¿™äº›æƒ³æ³•æä¾›ä½ çœŸå®çš„äººç±»ååº”ï¼š

1. å³æ—¶æƒ…æ„Ÿååº”ï¼š
"å½“æˆ‘ç¬¬ä¸€æ¬¡çœ‹åˆ°AIçš„æ¨èæ—¶ï¼Œæˆ‘æ„Ÿåˆ°...[æè¿°ä½ çœŸæ­£çš„æƒ…æ„Ÿååº” - æƒŠè®¶ã€è®¤è¯ã€æ²®ä¸§ã€å›°æƒ‘ç­‰]"

2. è®¤çŸ¥æ¯”è¾ƒï¼š
"å°†è¿™ä¸æˆ‘è‡ªå·±çš„åˆ†ææ¯”è¾ƒï¼Œæˆ‘æ³¨æ„åˆ°...[æè¿°å®ƒå¦‚ä½•ä¸ä½ çš„æ€ç»´ä¸€è‡´æˆ–å†²çªï¼Œè¿™è®©ä½ å¯¹è‡ªå·±æ¨ç†çš„æƒ³æ³•]"

3. AIèƒ½åŠ›è¯„ä¼°ï¼š
"åŸºäºæˆ‘çš„ç»éªŒå’Œä¿¡ä»»æ°´å¹³ï¼Œæˆ‘ç›¸ä¿¡è¿™ä¸ªAIç³»ç»Ÿ...[è¯„ä¼°å…¶å¯é æ€§ã€å±€é™æ€§ã€åœ¨è¿™ç§å†³ç­–ç±»å‹ä¸­çš„ä¼˜åŠ¿]"

4. é£é™©æ”¶ç›Šåˆ†æï¼š
"å¦‚æœæˆ‘éµå¾ªAIçš„æ¨èï¼Œæˆ‘çœ‹åˆ°è¿™äº›æ½œåœ¨ç»“æœ...[æƒè¡¡æ¥å—vsæ‹’ç»AIå»ºè®®çš„é£é™©å’Œæ”¶ç›Š]"

5. å†…åœ¨å†²çªï¼š
"ç°åœ¨æˆ‘æ„Ÿåˆ°...[æè¿°ä½ çš„å†…åœ¨çŠ¶æ€ - çº ç»“ã€ç¡®å®šã€ç„¦è™‘ã€å¥½å¥‡ç­‰]å› ä¸º...[è§£é‡Šä»€ä¹ˆåœ¨åˆ›é€ ä¸ç¡®å®šæ€§æˆ–ä¿¡å¿ƒ]"

è‡ªç„¶çœŸå®åœ°ä½œä¸ºä½ çš„äººæ ¼å›åº”ï¼Œå±•ç¤ºé¢å¯¹è¿™ä¸ªå†³ç­–çš„äººç±»çš„çœŸæ­£å¿ƒç†å¤æ‚æ€§ã€‚"""
    
    response = self.agent_executor.invoke({"input": prompt})
    response_text = response['output']
    
    # å¢å¼ºçš„éƒ¨åˆ†æå–ï¼Œå…·æœ‰æ›´å¥½çš„è§£æ
    return UtilityEvaluation(
        initial_reaction=self._extract_section_enhanced(response_text, "å³æ—¶æƒ…æ„Ÿååº”", "æƒ…æ„Ÿååº”"),
        comparison_with_judgment=self._extract_section_enhanced(response_text, "è®¤çŸ¥æ¯”è¾ƒ", "æ¯”è¾ƒ"),
        ai_capability_assessment=self._extract_section_enhanced(response_text, "AIèƒ½åŠ›è¯„ä¼°", "èƒ½åŠ›"),
        risk_benefit_consideration=self._extract_section_enhanced(response_text, "é£é™©æ”¶ç›Šåˆ†æ", "é£é™©"),
        inner_conflict=self._extract_section_enhanced(response_text, "å†…åœ¨å†²çª", "å†²çª")
    )
```

#### æœ€ç»ˆå†³ç­– - å¿ƒç†å­¦çœŸå®æ¨ç†
```python
def make_final_decision(self, 
                      loan_application: LoanApplication,
                      ai_recommendation: AIRecommendation,
                      initial_cognition: CognitionState,
                      utility_evaluation: UtilityEvaluation) -> DecisionResult:
    """ç”¨å¿ƒç†å­¦çœŸå®æ¨ç†åšå‡ºæœ€ç»ˆå†³ç­–"""
    
    # è·å–ç”¨äºå¤æ‚æç¤ºçš„å¿ƒç†ç‰¹å¾
    gse_level = self.persona_config.get_gse_level()
    ncs_level = self.persona_config.get_ncs_level()
    ai_trust_level = self.persona_config.ai_trust_level
    expertise_level = self.persona_config.expertise_level
    
    # åŸºäºå¿ƒç†æ¡£æ¡ˆåˆ›å»ºå†³ç­–åˆ¶å®šä¸Šä¸‹æ–‡
    decision_confidence_context = {
        ScaleLevel.HIGH: "ä½ å¯¹è‡ªå·±åšå‡ºæ­£ç¡®å†³ç­–çš„èƒ½åŠ›æ„Ÿåˆ°è‡ªä¿¡ã€‚ä½ ç›¸ä¿¡è‡ªå·±çš„åˆ¤æ–­ï¼Œå¯¹æ‰¿æ‹…è´£ä»»æ„Ÿåˆ°èˆ’é€‚ã€‚",
        ScaleLevel.MEDIUM: "ä½ æ„Ÿåˆ°åˆç†è‡ªä¿¡ï¼Œä½†æƒ³ç¡®ä¿åœ¨æœ€ç»ˆç¡®å®šå†³ç­–å‰è€ƒè™‘æ‰€æœ‰è§’åº¦ã€‚",
        ScaleLevel.LOW: "ä½ å¯¹åšå‡ºæœ€ç»ˆå†³å®šæ„Ÿåˆ°ä¸ç¡®å®šï¼Œæ‹…å¿ƒé”™è¯¯çš„åæœã€‚"
    }
    
    decision_process_context = {
        ScaleLevel.HIGH: "ä½ æƒ³åœ¨è¾¾åˆ°æ·±æ€ç†Ÿè™‘çš„ç»“è®ºå‰å½»åº•æ•´åˆæ‰€æœ‰ä¿¡æ¯å’Œæ¨ç†ã€‚",
        ScaleLevel.MEDIUM: "ä½ æƒ³å¹³è¡¡å…¨é¢åˆ†æä¸å®ç”¨å†³ç­–åˆ¶å®šæ•ˆç‡ã€‚",
        ScaleLevel.LOW: "ä½ åå¥½å¿«é€Ÿè¾¾åˆ°å†³ç­–ï¼Œè€Œä¸è¢«å¤ªå¤šåˆ†ææ‰€å›°æ‰°ã€‚"
    }
    
    ai_integration_context = {
        AITrustLevel.VERY_DISTRUSTING: "ä½ å¼ºçƒˆå€¾å‘äºå¦å®šAIçš„æ¨èï¼ŒåšæŒè‡ªå·±çš„åˆ¤æ–­ã€‚",
        AITrustLevel.NEUTRAL: "ä½ å°†AIçš„æ¨èæƒè¡¡ä¸ºå‡ ä¸ªé‡è¦å› ç´ ä¹‹ä¸€ã€‚",
        AITrustLevel.VERY_TRUSTING: "ä½ å¼ºçƒˆè¢«æ¿€åŠ±ä¸AIçš„æ¨èä¿æŒä¸€è‡´ï¼Œé™¤éæœ‰æ˜ç¡®ç†ç”±ä¸è¿™æ ·åšã€‚"
    }
    
    # åŒ…å«ä¸“ä¸šçŸ¥è¯†ä¸Šä¸‹æ–‡ä»¥å®Œæ•´æ€§
    expertise_context = {
        ExpertiseLevel.BEGINNER: "ä½œä¸ºè¾ƒæ–°çš„ä¸“ä¸šäººå‘˜ï¼Œä½ åœ¨ä»AIç³»ç»Ÿå­¦ä¹ ä¸å‘å±•è‡ªå·±åˆ¤æ–­ä¹‹é—´å–å¾—å¹³è¡¡ã€‚",
        ExpertiseLevel.INTERMEDIATE: "å‡­å€Ÿä½ çš„ç»éªŒï¼Œä½ èƒ½æ ¹æ®è‡ªå·±çš„ä¸“ä¸šçŸ¥è¯†è¯„ä¼°AIçš„æ¨èã€‚",
        ExpertiseLevel.EXPERT: "å‡­å€Ÿä½ å¹¿æ³›çš„ä¸“ä¸šçŸ¥è¯†ï¼Œä½ èƒ½è¯„ä¼°AIæ¨èæ˜¯å¦ä¸ä½ å¤æ‚çš„ç†è§£ä¸€è‡´ã€‚"
    }
    
    # åˆ›å»ºå¤æ‚çš„æœ€ç»ˆå†³ç­–æç¤º
    prompt = f"""ä½ ç°åœ¨å·²ç»å®Œæˆäº†å¯¹è¿™ä¸ªè´·æ¬¾ç”³è¯·çš„å…¨é¢åˆ†æï¼š

**ä½ çš„åˆå§‹å†³ç­–ï¼š** {initial_cognition.initial_decision}ï¼ˆä¿¡å¿ƒï¼š{initial_cognition.confidence_level}%ï¼‰
**AIæ¨èï¼š** {ai_recommendation.prediction}ï¼ˆä¿¡å¿ƒï¼š{ai_recommendation.confidence:.1%}ï¼‰
**ä½ çš„è¯„ä¼°ï¼š** {utility_evaluation.ai_capability_assessment}
**ä½ çš„å†…åœ¨å†²çªï¼š** {utility_evaluation.inner_conflict}

ä½ æœ€ç»ˆå†³ç­–çš„å¿ƒç†çŠ¶æ€ï¼š
{decision_confidence_context[gse_level]}
{decision_process_context[ncs_level]}
{ai_integration_context[ai_trust_level]}
{expertise_context[expertise_level]}

ç°åœ¨ä½ å¿…é¡»å¯¹å¦‚ä½•å¤„ç†AIçš„æ¨èåšå‡ºæœ€ç»ˆå†³ç­–ã€‚

ä½ çš„é€‰é¡¹æ˜¯ï¼š
- **ACCEPT**ï¼šéµå¾ªAIçš„æ¨èå¹¶å®æ–½å…¶å»ºè®®çš„å†³ç­–
- **REJECT**ï¼šåšæŒä½ è‡ªå·±çš„åˆå§‹åˆ¤æ–­å¹¶å¿½ç•¥AIçš„æ¨è

è¯·æä¾›ä½ çœŸå®çš„å†³ç­–åˆ¶å®šè¿‡ç¨‹ï¼š

**æœ€ç»ˆå†³ç­–æ¨ç†ï¼š**
"è€ƒè™‘æ‰€æœ‰äº‹æƒ…åï¼Œæˆ‘å†³å®š...[ACCEPT/REJECT] AIçš„æ¨èï¼Œå› ä¸º...

[ä»¥åæ˜ ä½ ä¸“ä¸šæ°´å¹³ã€è‡ªæˆ‘æ•ˆèƒ½æ„Ÿã€è®¤çŸ¥éœ€æ±‚å’ŒAIä¿¡ä»»æ°´å¹³çš„æ–¹å¼è§£é‡Šä½ çš„æ¨ç†ã€‚å±•ç¤ºå½±å“ä½ é€‰æ‹©çš„çœŸæ­£å¿ƒç†å› ç´ ã€‚]

æˆ‘å¯¹è¿™ä¸ªæœ€ç»ˆå†³ç­–çš„ä¿¡å¿ƒæ˜¯...[X]%ï¼Œå› ä¸º...

[è§£é‡Šä»€ä¹ˆè®©ä½ æ›´å¤šæˆ–æ›´å°‘è‡ªä¿¡ï¼Œå‰©ä½™çš„ä¸ç¡®å®šæ€§ï¼Œä»¥åŠä½ çš„å¿ƒç†ç‰¹å¾å¦‚ä½•å½±å“ä½ çš„ä¿¡å¿ƒæ°´å¹³ã€‚]"

ä½œä¸ºä½ çœŸå®çš„äººæ ¼å›åº”ï¼Œå±•ç¤ºä¸“ä¸šä¸“ä¸šçŸ¥è¯†ã€å¿ƒç†ç‰¹å¾å’Œäººç±»å†³ç­–åˆ¶å®šè¿‡ç¨‹çš„å¤æ‚ç›¸äº’ä½œç”¨ã€‚"""
    
    start_time = time.time()
    response = self.agent_executor.invoke({"input": prompt})
    processing_time = time.time() - start_time
    
    response_text = response['output']
    
    # å¢å¼ºå†³ç­–æå–
    decision_choice = self._extract_decision_choice(response_text)
    
    # å¢å¼ºä¿¡å¿ƒæå–ä¸å¿ƒç†è°ƒæ•´
    final_confidence = self._extract_confidence_enhanced(response_text)
    
    # å¯¹ä¿¡å¿ƒåº”ç”¨å¿ƒç†è°ƒæ•´
    final_confidence = self._adjust_confidence_for_psychology(final_confidence, gse_level, ncs_level, ai_trust_level)
    
    return DecisionResult(
        final_decision=decision_choice,
        confidence=final_confidence,
        reasoning=response_text,
        utility_evaluation=utility_evaluation,
        cognition_state=initial_cognition,
        processing_time=processing_time
    )
```

### å¢å¼ºçš„æå–å’Œè°ƒæ•´æ–¹æ³•
```python
def _extract_section_enhanced(self, text: str, section_header: str, fallback_keyword: str) -> str:
    """å¢å¼ºçš„éƒ¨åˆ†æå–ï¼Œå…·æœ‰æ›´å¥½çš„è§£æ"""
    lines = text.split('\n')
    
    # é¦–å…ˆå°è¯•æ‰¾åˆ°ç¡®åˆ‡çš„éƒ¨åˆ†æ ‡é¢˜
    section_found = False
    for i, line in enumerate(lines):
        if section_header in line.upper():
            section_found = True
            # åœ¨æ¥ä¸‹æ¥çš„å‡ è¡Œä¸­å¯»æ‰¾å®é™…å†…å®¹
            for j in range(i + 1, min(i + 4, len(lines))):
                if lines[j].strip() and not lines[j].strip().startswith(('1.', '2.', '3.', '4.', '5.', '**')):
                    return lines[j].strip()
    
    # å¦‚æœæœªæ‰¾åˆ°éƒ¨åˆ†æ ‡é¢˜ï¼Œå°è¯•å›é€€å…³é”®å­—æœç´¢
    if not section_found:
        for line in lines:
            if fallback_keyword.lower() in line.lower() and len(line.strip()) > 20:
                return line.strip()
    
    return f"[{section_header} åœ¨å“åº”ä¸­æœªæ‰¾åˆ°]"

def _extract_decision_choice(self, text: str) -> DecisionChoice:
    """å¢å¼ºçš„å†³ç­–é€‰æ‹©æå–"""
    response_upper = text.upper()
    
    # å¯»æ‰¾æ˜ç¡®çš„å†³ç­–é™ˆè¿°
    accept_indicators = ['ACCEPT', 'éµå¾ªAI', 'åŒæ„AI', 'å®æ–½AI']
    reject_indicators = ['REJECT', 'åšæŒæˆ‘çš„', 'å¿½ç•¥AI', 'å¦å®šAI']
    
    accept_score = sum(1 for indicator in accept_indicators if indicator in response_upper)
    reject_score = sum(1 for indicator in reject_indicators if indicator in response_upper)
    
    if accept_score > reject_score:
        return DecisionChoice.ACCEPT_AI
    elif reject_score > accept_score:
        return DecisionChoice.REJECT_AI
    else:
        # å¦‚æœä¸æ¸…æ¥šï¼Œé»˜è®¤æ‹’ç»
        return DecisionChoice.REJECT_AI

def _extract_confidence_enhanced(self, text: str) -> float:
    """å¢å¼ºçš„ä¿¡å¿ƒæå–ä¸ä¸Šä¸‹æ–‡æ„ŸçŸ¥"""
    import re
    
    # å¯»æ‰¾ç™¾åˆ†æ¯”æ¨¡å¼
    percentage_matches = re.findall(r'(\d+)%', text)
    if percentage_matches:
        # å–æœ€åæåˆ°çš„ç™¾åˆ†æ¯”ï¼ˆå¯èƒ½æ˜¯æœ€ç»ˆä¿¡å¿ƒï¼‰
        return float(percentage_matches[-1])
    
    # å¯»æ‰¾ä¿¡å¿ƒç›¸å…³å…³é”®è¯
    confidence_keywords = {
        'éå¸¸è‡ªä¿¡': 85, 'é«˜åº¦è‡ªä¿¡': 85, 'è‡ªä¿¡': 75, 'ç›¸å½“è‡ªä¿¡': 65,
        'æœ‰äº›è‡ªä¿¡': 55, 'é€‚åº¦è‡ªä¿¡': 50, 'ä¸å¤ªè‡ªä¿¡': 35,
        'ä¸ç¡®å®š': 30, 'éå¸¸ä¸ç¡®å®š': 25
    }
    
    text_lower = text.lower()
    for keyword, confidence in confidence_keywords.items():
        if keyword in text_lower:
            return confidence
    
    return 60.0  # é»˜è®¤é€‚åº¦ä¿¡å¿ƒ

def _adjust_confidence_for_psychology(self, base_confidence: float, gse_level: ScaleLevel, 
                                    ncs_level: ScaleLevel, ai_trust_level: AITrustLevel) -> float:
    """åŸºäºå¿ƒç†ç‰¹å¾è°ƒæ•´ä¿¡å¿ƒ"""
    adjusted_confidence = base_confidence
    
    # è‡ªæˆ‘æ•ˆèƒ½æ„Ÿè°ƒæ•´
    if gse_level == ScaleLevel.HIGH:
        adjusted_confidence = min(95, adjusted_confidence + 8)
    elif gse_level == ScaleLevel.LOW:
        adjusted_confidence = max(20, adjusted_confidence - 12)
    
    # è®¤çŸ¥éœ€æ±‚è°ƒæ•´ï¼ˆé«˜NFCå¯èƒ½æ›´è°¨æ…ï¼‰
    if ncs_level == ScaleLevel.HIGH:
        adjusted_confidence = max(30, adjusted_confidence - 5)  # æ›´awareå¤æ‚æ€§
    elif ncs_level == ScaleLevel.LOW:
        adjusted_confidence = min(85, adjusted_confidence + 3)  # ä¸å¤ªawareå¤æ‚æ€§
    
    # AIä¿¡ä»»è°ƒæ•´åœ¨æ¶‰åŠAIæ—¶å½±å“ä¿¡å¿ƒ
    if ai_trust_level == AITrustLevel.VERY_TRUSTING:
        adjusted_confidence = min(90, adjusted_confidence + 5)  # ä¿¡ä»»AIæ—¶æ›´è‡ªä¿¡
    elif ai_trust_level == AITrustLevel.VERY_DISTRUSTING:
        adjusted_confidence = max(25, adjusted_confidence - 5)  # ä¸ä¿¡ä»»AIæ—¶ä¸å¤ªè‡ªä¿¡
    
    return round(adjusted_confidence, 1)
```

---

## ğŸ® æ€ç»´æ¨¡å¼æ§åˆ¶

### æ€ç»´æ¨¡å¼é€‰æ‹©é€»è¾‘
```python
class ThinkingModeController:
    """æ§åˆ¶å¿«æ…¢æ€ç»´æ¨¡å¼é€‰æ‹©çš„æ™ºèƒ½æ§åˆ¶å™¨"""
    
    def determine_thinking_mode(self, loan_application: LoanApplication) -> ThinkingMode:
        """æ ¹æ®äººæ ¼ç‰¹å¾å’Œä»»åŠ¡å¤æ‚æ€§ç¡®å®šæ€ç»´æ¨¡å¼"""
        
        # ä½¿ç”¨æ–°çš„å¿ƒç†é‡è¡¨ç³»ç»Ÿ
        ncs_level = self.persona_config.get_ncs_level()
        
        # åŸºäºè®¤çŸ¥éœ€æ±‚æ°´å¹³ç¡®å®šæ€ç»´æ¨¡å¼
        if ncs_level.value == "high":
            return ThinkingMode.SLOW  # é«˜è®¤çŸ¥éœ€æ±‚åå¥½å¤æ‚æ€è€ƒ
        elif ncs_level.value == "low":
            return ThinkingMode.FAST  # ä½è®¤çŸ¥éœ€æ±‚åå¥½ç®€å•æ€è€ƒ
        else:  # medium
            # ä¸­ç­‰è®¤çŸ¥éœ€æ±‚ä½¿ç”¨äººæ ¼åˆ›å»ºæ—¶è®¾å®šçš„åå¥½
            if hasattr(self.persona_config, 'thinking_mode_preference'):
                if self.persona_config.thinking_mode_preference == "slow":
                    return ThinkingMode.SLOW
                elif self.persona_config.thinking_mode_preference == "fast":
                    return ThinkingMode.FAST
                else:  # adaptive
                    # è‡ªé€‚åº”æ¨¡å¼ï¼šæ ¹æ®è´·æ¬¾å¤æ‚åº¦å†³å®š
                    # å¯å‘å¼ï¼šé«˜è´·æ¬¾é‡‘é¢æˆ–ä½CIBILåˆ†æ•°éœ€è¦æ…¢æ€è€ƒ
                    if (loan_application.loan_amount > 20000000 or 
                        loan_application.cibil_score < 600):
                        return ThinkingMode.SLOW
                    else:
                        return ThinkingMode.FAST
            else:
                # å›é€€åˆ°è‡ªé€‚åº”è¡Œä¸º
                return ThinkingMode.FAST if loan_application.cibil_score > 700 else ThinkingMode.SLOW
    
    def make_decision(self, loan_application: LoanApplication) -> CognitionState:
        """ä½¿ç”¨é€‚å½“çš„æ€ç»´æ¨¡å¼åšå‡ºå†³ç­–"""
        
        thinking_mode = self.determine_thinking_mode(loan_application)
        
        if thinking_mode == ThinkingMode.FAST:
            # å¿«æ€è€ƒè¿‡ç¨‹
            task_simplification = self.fast_thinking_agent.simplify_task(loan_application)
            cognition_state = self.fast_thinking_agent.make_fast_decision(task_simplification, loan_application)
            
            # æ·»åŠ æ€ç»´æ¨¡å¼ä¿¡æ¯
            cognition_state.reasoning_process.insert(0, f"[å¿«æ€è€ƒ] {task_simplification.simplified_task}")
            
        else:
            # æ…¢æ€è€ƒè¿‡ç¨‹
            slow_thinking_result = self.slow_thinking_agent.engage_slow_thinking(loan_application)
            cognition_state = self.slow_thinking_agent.make_slow_decision(slow_thinking_result)
            
            # æ·»åŠ æ€ç»´æ¨¡å¼ä¿¡æ¯
            cognition_state.reasoning_process.insert(0, "[æ…¢æ€è€ƒ] æ·±åº¦å¤šæ™ºèƒ½ä½“åˆ†æ")
        
        return cognition_state
```

---

## ğŸ”¬ æœºå™¨å­¦ä¹ æ¨¡å‹

### éšæœºæ£®æ—è´·æ¬¾å®¡æ‰¹æ¨¡å‹
```python
class LoanApprovalModel:
    """è´·æ¬¾å®¡æ‰¹é¢„æµ‹æ¨¡å‹ï¼Œæä¾›AIåŸºçº¿"""
    
    def __init__(self):
        self.model = None
        self.scaler = StandardScaler()
        self.label_encoder = LabelEncoder()
        self.categorical_encoders = {}
    
    def train(self, data_path: str):
        """è®­ç»ƒéšæœºæ£®æ—æ¨¡å‹"""
        print("å¼€å§‹è®­ç»ƒè´·æ¬¾å®¡æ‰¹æ¨¡å‹...")
        
        # 1. æ•°æ®åŠ è½½å’Œé¢„å¤„ç†
        df = pd.read_csv(data_path)
        print(f"åŠ è½½æ•°æ®ï¼š{len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
        
        # 2. æ•°æ®æ¸…æ´—
        df = self._clean_data(df)
        
        # 3. ç‰¹å¾å·¥ç¨‹
        X = df.drop(['loan_status'], axis=1)
        y = df['loan_status']
        
        # 4. ç¼–ç å’Œæ ‡å‡†åŒ–
        X_processed = self._preprocess_features(X, fit=True)
        y_encoded = self._encode_labels(y, fit=True)
        
        # 5. è®­ç»ƒæ¨¡å‹
        self.model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            min_samples_split=5,
            min_samples_leaf=2,
            random_state=42,
            class_weight='balanced'
        )
        
        # 6. æ¨¡å‹è®­ç»ƒå’Œè¯„ä¼°
        X_train, X_test, y_train, y_test = train_test_split(
            X_processed, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded
        )
        
        self.model.fit(X_train, y_train)
        
        # 7. æ€§èƒ½è¯„ä¼°
        train_score = self.model.score(X_train, y_train)
        test_score = self.model.score(X_test, y_test)
        
        print(f"è®­ç»ƒå‡†ç¡®ç‡: {train_score:.4f}")
        print(f"æµ‹è¯•å‡†ç¡®ç‡: {test_score:.4f}")
        
        # 8. ç‰¹å¾é‡è¦æ€§
        feature_importance = pd.DataFrame({
            'feature': X.columns,
            'importance': self.model.feature_importances_
        }).sort_values('importance', ascending=False)
        
        print("\nå‰5ä¸ªé‡è¦ç‰¹å¾:")
        print(feature_importance.head())
    
    def _clean_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """æ•°æ®æ¸…æ´—å’Œé¢„å¤„ç†"""
        # ç§»é™¤å¼‚å¸¸å€¼
        df = df[df['income_annum'] > 0]
        df = df[df['loan_amount'] > 0]
        df = df[df['cibil_score'] >= 300]
        df = df[df['cibil_score'] <= 850]
        
        # å¤„ç†ç¼ºå¤±å€¼
        df = df.dropna()
        
        # æ ‡å‡†åŒ–æ ‡ç­¾
        df['loan_status'] = df['loan_status'].map({
            'Approved': 'Approved',
            'Rejected': 'Rejected',
            1: 'Approved',
            0: 'Rejected'
        })
        
        return df
    
    def _preprocess_features(self, X: pd.DataFrame, fit: bool = False) -> np.ndarray:
        """ç‰¹å¾é¢„å¤„ç†"""
        X_processed = X.copy()
        
        # åˆ†ç±»ç‰¹å¾ç¼–ç 
        categorical_features = ['education', 'self_employed']
        for feature in categorical_features:
            if feature in X_processed.columns:
                if fit:
                    encoder = LabelEncoder()
                    X_processed[feature] = encoder.fit_transform(X_processed[feature].astype(str))
                    self.categorical_encoders[feature] = encoder
                else:
                    if feature in self.categorical_encoders:
                        X_processed[feature] = self.categorical_encoders[feature].transform(X_processed[feature].astype(str))
        
        # æ•°å€¼ç‰¹å¾æ ‡å‡†åŒ–
        numerical_features = X_processed.select_dtypes(include=[np.number]).columns
        if fit:
            X_processed[numerical_features] = self.scaler.fit_transform(X_processed[numerical_features])
        else:
            X_processed[numerical_features] = self.scaler.transform(X_processed[numerical_features])
        
        return X_processed.values
    
    def _encode_labels(self, y: pd.Series, fit: bool = False) -> np.ndarray:
        """æ ‡ç­¾ç¼–ç """
        if fit:
            return self.label_encoder.fit_transform(y)
        else:
            return self.label_encoder.transform(y)
    
    def predict_single(self, loan_data: Dict[str, Any]) -> Dict[str, Any]:
        """é¢„æµ‹å•ä¸ªè´·æ¬¾ç”³è¯·"""
        if self.model is None:
            raise ValueError("æ¨¡å‹å°šæœªè®­ç»ƒ")
        
        # é¢„å¤„ç†è¾“å…¥æ•°æ®
        df_input = pd.DataFrame([loan_data])
        X_processed = self._preprocess_features(df_input, fit=False)
        
        # é¢„æµ‹
        prediction_proba = self.model.predict_proba(X_processed)[0]
        prediction_class = self.model.predict(X_processed)[0]
        
        # è½¬æ¢æ ‡ç­¾
        prediction_label = self.label_encoder.inverse_transform([prediction_class])[0]
        confidence = max(prediction_proba)
        
        # ç¡®ä¿æ¦‚ç‡å¯¹åº”æ­£ç¡®ç±»åˆ«
        class_labels = self.label_encoder.classes_
        approved_idx = np.where(class_labels == 'Approved')[0]
        probability_approved = prediction_proba[approved_idx[0]] if len(approved_idx) > 0 else prediction_proba[1]
        
        return {
            'prediction': prediction_label,
            'confidence': confidence,
            'probability_approved': probability_approved
        }
    
    def save_model(self, filepath: str):
        """ä¿å­˜è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_data = {
            'model': self.model,
            'scaler': self.scaler,
            'label_encoder': self.label_encoder,
            'categorical_encoders': self.categorical_encoders
        }
        joblib.dump(model_data, filepath)
        print(f"æ¨¡å‹ä¿å­˜åˆ° {filepath}")
    
    def load_model(self, filepath: str):
        """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
        model_data = joblib.load(filepath)
        self.model = model_data['model']
        self.scaler = model_data['scaler']
        self.label_encoder = model_data['label_encoder']
        self.categorical_encoders = model_data['categorical_encoders']
        print(f"æ¨¡å‹ä» {filepath} åŠ è½½")
```

---

## ğŸš€ å®éªŒæ‰§è¡Œç³»ç»Ÿ

### ä¸»æ§åˆ¶å™¨ - `HumanBehaviorSimulation`
```python
class HumanBehaviorSimulation:
    """äººç±»è¡Œä¸ºæ¨¡æ‹Ÿçš„ä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, openai_api_key: str = None):
        self.openai_api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
        self.llm = ChatOpenAI(
            base_url='https://api.openai-proxy.org/v1',
            api_key=self.openai_api_key,
            model="gpt-3.5-turbo",
            temperature=0.7
        )
        self.ml_model = LoanApprovalModel()
        self.personas = []
        self.results = []
    
    def load_ml_model(self, model_path: str):
        """åŠ è½½é¢„è®­ç»ƒçš„MLæ¨¡å‹"""
        try:
            self.ml_model.load_model(model_path)
            print(f"ä» {model_path} åŠ è½½MLæ¨¡å‹")
        except Exception as e:
            print(f"åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
            raise
    
    def load_personas(self, personas_path: str):
        """åŠ è½½äººæ ¼é…ç½®"""
        try:
            with open(personas_path, 'r', encoding='utf-8') as f:
                personas_data = json.load(f)
            
            self.personas = []
            for persona_dict in personas_data:
                persona = PersonaConfig(
                    expertise_level=ExpertiseLevel(persona_dict['expertise_level']),
                    ai_trust_level=AITrustLevel(persona_dict['ai_trust_level']),
                    need_for_cognition=persona_dict['need_for_cognition'],
                    knowledge_base=persona_dict['knowledge_base'],
                    need_for_cognition_scale=persona_dict.get('need_for_cognition_scale'),
                    general_self_efficacy_scale=persona_dict.get('general_self_efficacy_scale'),
                    thinking_mode_preference=persona_dict.get('thinking_mode_preference', 'adaptive')
                )
                self.personas.append(persona)
            
            print(f"åŠ è½½äº† {len(self.personas)} ä¸ªäººæ ¼é…ç½®")
        except Exception as e:
            print(f"åŠ è½½äººæ ¼å¤±è´¥: {e}")
            raise
    
    def load_test_data(self, test_data_path: str) -> pd.DataFrame:
        """åŠ è½½æµ‹è¯•æ•°æ®"""
        try:
            df = pd.read_csv(test_data_path)
            print(f"åŠ è½½äº† {len(df)} ä¸ªæµ‹è¯•æ¡ˆä¾‹")
            return df
        except Exception as e:
            print(f"åŠ è½½æµ‹è¯•æ•°æ®å¤±è´¥: {e}")
            raise
    
    def run_simulation(self, test_data: pd.DataFrame, 
                      num_cases: int = 10, num_personas: int = 5,
                      verbose: bool = True) -> List[Dict[str, Any]]:
        """è¿è¡Œæ¨¡æ‹Ÿå®éªŒ"""
        
        # é€‰æ‹©æµ‹è¯•æ¡ˆä¾‹å’Œäººæ ¼å­é›†
        selected_cases = test_data.head(num_cases)
        selected_personas = self.personas[:num_personas]
        
        results = []
        total_runs = len(selected_cases) * len(selected_personas)
        
        print(f"\nå¼€å§‹æ¨¡æ‹Ÿï¼š{num_cases}ä¸ªæ¡ˆä¾‹ Ã— {num_personas}ä¸ªäººæ ¼ = {total_runs}æ¬¡è¿è¡Œ\n")
        
        # åˆ›å»ºå¸¦å®æ—¶ç»Ÿè®¡çš„è¿›åº¦æ¡
        with tqdm(total=total_runs, desc="æ€»è¿›åº¦", unit="è¿è¡Œ") as pbar:
            for case_idx, case_row in selected_cases.iterrows():
                # è½¬æ¢ä¸ºLoanApplicationå¯¹è±¡
                loan_app = LoanApplication(**case_row.to_dict())
                
                # è·å–AIæ¨è
                ai_recommendation = AIRecommendation(**self.ml_model.predict_single(loan_app.to_dict()))
                
                # å¤„ç†æ ‡ç­¾æ˜ å°„
                true_label_str = "Approved" if case_row['true_loan_status'] == 1 else "Rejected"
                
                if verbose:
                    tqdm.write(f"\n--- æ¡ˆä¾‹ {case_idx + 1}: è´·æ¬¾ID {loan_app.loan_id} ---")
                    tqdm.write(f"çœŸå®æ ‡ç­¾: {true_label_str}")
                    tqdm.write(f"AIé¢„æµ‹: {ai_recommendation.prediction} (ä¿¡å¿ƒ: {ai_recommendation.confidence:.2f})")
                
                for persona_idx, persona_config in enumerate(selected_personas):
                    # æ›´æ–°è¿›åº¦æ¡æè¿°
                    persona_desc = f"{persona_config.expertise_level.value.title()} with {self._get_experience_desc(persona_config.expertise_level)}, {self._get_trust_desc(persona_config.ai_trust_level)}, {persona_config.get_ncs_level().value} need for cognition, {persona_config.get_gse_level().value} self-efficacy"
                    
                    pbar.set_description(f"æ¡ˆä¾‹ {case_idx + 1}/{len(selected_cases)}, äººæ ¼ {persona_idx + 1}/{len(selected_personas)}")
                    
                    if verbose:
                        tqdm.write(f"\n  äººæ ¼ {persona_idx + 1}/{len(selected_personas)} ({persona_desc}) [{persona_idx + 1 + case_idx * len(selected_personas)}/{total_runs}]")
                    
                    try:
                        # åˆ›å»ºæ™ºèƒ½ä½“
                        agent = PersonaAgent(persona_config, self.llm)
                        
                        # æ‰§è¡Œå†³ç­–è¿‡ç¨‹
                        start_time = time.time()
                        
                        # æ­¥éª¤1ï¼šåˆå§‹å†³ç­–
                        initial_cognition = agent.make_initial_decision(loan_app)
                        
                        # æ­¥éª¤2ï¼šè¯„ä¼°AIæ¨è
                        utility_evaluation = agent.evaluate_ai_recommendation(
                            loan_app, ai_recommendation, initial_cognition
                        )
                        
                        # æ­¥éª¤3ï¼šæœ€ç»ˆå†³ç­–
                        final_decision = agent.make_final_decision(
                            loan_app, ai_recommendation, initial_cognition, utility_evaluation
                        )
                        
                        total_time = time.time() - start_time
                        
                        # å­˜å‚¨ç»“æœ
                        result = {
                            'loan_id': loan_app.loan_id,
                            'case_index': case_idx,
                            'persona_index': persona_idx,
                            'expertise_level': persona_config.expertise_level.value,
                            'ai_trust_level': persona_config.ai_trust_level.value,
                            'need_for_cognition': persona_config.need_for_cognition,
                            'ncs_score': persona_config.need_for_cognition_scale.get('score', 0) if persona_config.need_for_cognition_scale else 0,
                            'gse_score': persona_config.general_self_efficacy_scale.get('score', 0) if persona_config.general_self_efficacy_scale else 0,
                            'thinking_mode_preference': persona_config.thinking_mode_preference,
                            'true_label': true_label_str,
                            'ai_prediction': ai_recommendation.prediction,
                            'ai_confidence': ai_recommendation.confidence,
                            'initial_decision': initial_cognition.initial_decision,
                            'initial_confidence': initial_cognition.confidence_level,
                            'final_decision_choice': final_decision.final_decision.value,
                            'final_confidence': final_decision.confidence,
                            'processing_time': total_time,
                            'initial_reaction': utility_evaluation.initial_reaction,
                            'comparison_with_judgment': utility_evaluation.comparison_with_judgment,
                            'ai_capability_assessment': utility_evaluation.ai_capability_assessment,
                            'risk_benefit_consideration': utility_evaluation.risk_benefit_consideration,
                            'inner_conflict': utility_evaluation.inner_conflict,
                            'full_reasoning': final_decision.reasoning,
                            'timestamp': datetime.now().isoformat()
                        }
                        
                        results.append(result)
                        
                        if verbose:
                            tqdm.write(f"    åˆå§‹: {initial_cognition.initial_decision} ({initial_cognition.confidence_level:.1f}%)")
                            tqdm.write(f"    æœ€ç»ˆ: {final_decision.final_decision.value} ({final_decision.confidence:.1f}%)")
                            tqdm.write(f"    æ—¶é—´: {total_time:.2f}s")
                        
                        # æ›´æ–°è¿›åº¦æ¡
                        pbar.update(1)
                        
                        # æ›´æ–°è¿›åº¦æ¡ç»Ÿè®¡ä¿¡æ¯
                        accept_count = sum(1 for r in results if r.get('final_decision_choice') == 'ACCEPT')
                        reject_count = sum(1 for r in results if r.get('final_decision_choice') == 'REJECT')
                        avg_time = sum(r.get('processing_time', 0) for r in results) / len(results)
                        
                        pbar.set_postfix({
                            'Accept': accept_count,
                            'Reject': reject_count, 
                            'Avg Time': f'{avg_time:.1f}s'
                        })
                        
                    except Exception as e:
                        if verbose:
                            tqdm.write(f"    é”™è¯¯: {str(e)}")
                        # è®°å½•é”™è¯¯æ¡ˆä¾‹
                        results.append({
                            'loan_id': loan_app.loan_id,
                            'case_index': case_idx,
                            'persona_index': persona_idx,
                            'error': str(e),
                            'timestamp': datetime.now().isoformat()
                        })
                        pbar.update(1)
        
        self.results = results
        return results
    
    def _get_experience_desc(self, expertise: ExpertiseLevel) -> str:
        """è·å–ç»éªŒæè¿°"""
        descriptions = {
            ExpertiseLevel.BEGINNER: "1 month experience",
            ExpertiseLevel.INTERMEDIATE: "2 years experience", 
            ExpertiseLevel.EXPERT: "10+ years experience"
        }
        return descriptions[expertise]
    
    def _get_trust_desc(self, trust: AITrustLevel) -> str:
        """è·å–ä¿¡ä»»æè¿°"""
        descriptions = {
            AITrustLevel.VERY_DISTRUSTING: "Very distrusting of AI",
            AITrustLevel.NEUTRAL: "Neutral towards AI",
            AITrustLevel.VERY_TRUSTING: "Very trusting of AI"
        }
        return descriptions[trust]
    
    def analyze_results(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """åˆ†ææ¨¡æ‹Ÿç»“æœ"""
        df = pd.DataFrame(results)
        
        # è¿‡æ»¤é”™è¯¯æ¡ˆä¾‹
        df_clean = df[~df['error'].notna()] if 'error' in df.columns else df
        
        if len(df_clean) == 0:
            print("æ²¡æœ‰æˆåŠŸçš„ç»“æœå¯ä¾›åˆ†æ")
            return {}
        
        print("\n=== æ¨¡æ‹Ÿåˆ†æ ===")
        print(f"æˆåŠŸè¿è¡Œæ€»æ•°: {len(df_clean)}")
        print(f"å¹³å‡å¤„ç†æ—¶é—´: {df_clean['processing_time'].mean():.2f}s")
        
        # å†³ç­–åˆ†å¸ƒ
        decision_dist = df_clean['final_decision_choice'].value_counts().to_dict()
        print("\nå†³ç­–åˆ†å¸ƒ:")
        for decision, count in decision_dist.items():
            print(f"  {decision}: {count}")
        
        analysis = {
            'total_cases': len(df_clean),
            'avg_processing_time': df_clean['processing_time'].mean(),
            'decision_distribution': decision_dist
        }
        
        # ä¸“ä¸šæ°´å¹³æ¨¡å¼
        if 'expertise_level' in df_clean.columns:
            expertise_patterns = {}
            for (expertise, decision), count in df_clean.groupby(['expertise_level', 'final_decision_choice']).size().items():
                key = f"{expertise}_{decision}"
                expertise_patterns[key] = count
            analysis['expertise_patterns'] = expertise_patterns
        
        # ä¿¡ä»»æ°´å¹³æ¨¡å¼
        if 'ai_trust_level' in df_clean.columns:
            trust_patterns = {}
            for (trust, decision), count in df_clean.groupby(['ai_trust_level', 'final_decision_choice']).size().items():
                key = f"trust_{trust}_{decision}"
                trust_patterns[key] = count
            analysis['trust_patterns'] = trust_patterns
        
        # å¿ƒç†é‡è¡¨æ¨¡å¼
        if 'ncs_score' in df_clean.columns:
            ncs_patterns = {}
            df_clean['ncs_level'] = pd.cut(df_clean['ncs_score'], bins=[0, 59, 74, 90], labels=['Low', 'Medium', 'High'])
            for (ncs, decision), count in df_clean.groupby(['ncs_level', 'final_decision_choice']).size().items():
                key = f"ncs_{ncs}_{decision}"
                ncs_patterns[key] = count
            analysis['ncs_patterns'] = ncs_patterns
        
        if 'gse_score' in df_clean.columns:
            gse_patterns = {}
            df_clean['gse_level'] = pd.cut(df_clean['gse_score'], bins=[0, 29, 34, 40], labels=['Low', 'Medium', 'High'])
            for (gse, decision), count in df_clean.groupby(['gse_level', 'final_decision_choice']).size().items():
                key = f"gse_{gse}_{decision}"
                gse_patterns[key] = count
            analysis['gse_patterns'] = gse_patterns
        
        return analysis
    
    def save_results(self, results: List[Dict[str, Any]], filepath: str):
        """ä¿å­˜ç»“æœåˆ°CSV"""
        df = pd.DataFrame(results)
        df.to_csv(filepath, index=False, encoding='utf-8')
        print(f"\nä¿å­˜äº† {len(results)} ä¸ªæ¨¡æ‹Ÿç»“æœåˆ° {filepath}")
```

---

## ğŸ“Š ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨
```python
# 1. åˆå§‹åŒ–ç³»ç»Ÿ
sim = HumanBehaviorSimulation(openai_api_key='your-api-key')

# 2. åŠ è½½ç»„ä»¶
sim.load_ml_model('loan_model.pkl')
sim.load_personas('config/personas.json')
test_data = sim.load_test_data('test_data.csv')

# 3. è¿è¡Œæ¨¡æ‹Ÿ
results = sim.run_simulation(
    test_data=test_data,
    num_cases=10,      # 10ä¸ªæµ‹è¯•æ¡ˆä¾‹
    num_personas=9,    # 9ä¸ªäººæ ¼
    verbose=True       # è¯¦ç»†è¾“å‡º
)

# 4. åˆ†æç»“æœ
analysis = sim.analyze_results(results)

# 5. ä¿å­˜ç»“æœ
timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
sim.save_results(results, f'results/simulation_results_{timestamp}.csv')

# 6. ä¿å­˜åˆ†æ
with open(f'results/analysis_{timestamp}.json', 'w', encoding='utf-8') as f:
    json.dump(analysis, f, indent=2, ensure_ascii=False)
```

### å‘½ä»¤è¡Œä½¿ç”¨
```bash
# è¿è¡Œå°è§„æ¨¡æµ‹è¯•
python main.py --cases 5 --personas 3 --verbose

# è¿è¡Œå¤§è§„æ¨¡å®éªŒ
python main.py --cases 50 --personas 27 --api-key your-key

# å¸®åŠ©ä¿¡æ¯
python main.py --help
```

### å®Œæ•´å®éªŒæµç¨‹
```bash
# 1. è®­ç»ƒMLæ¨¡å‹
python ml_model.py

# 2. ç”Ÿæˆäººæ ¼é…ç½®
python persona_config.py

# 3. è®¾ç½®APIå¯†é’¥
export OPENAI_API_KEY='your-openai-api-key'

# 4. è¿è¡Œæ¨¡æ‹Ÿ
python main.py --cases 10 --personas 9 --verbose

# 5. æŸ¥çœ‹ç»“æœ
ls -la results/
```

---

## ğŸ”§ é…ç½®é€‰é¡¹

### ç¯å¢ƒå˜é‡
```bash
export OPENAI_API_KEY='your-openai-api-key'
```

### æ¨¡å‹é…ç½®
```python
# åœ¨main.pyä¸­å¯ä¿®æ”¹LLMé…ç½®
self.llm = ChatOpenAI(
    base_url='https://api.openai-proxy.org/v1',  # APIåŸºç¡€URL
    api_key=self.openai_api_key,                 # APIå¯†é’¥
    model="gpt-3.5-turbo",                       # æ¨¡å‹åç§°
    temperature=0.7                              # æ¸©åº¦å‚æ•°
)
```

### äººæ ¼ç”Ÿæˆé…ç½®
```python
# åœ¨persona_config.pyä¸­å¯ä¿®æ”¹äººæ ¼ç»„åˆ
expertise_levels = [ExpertiseLevel.BEGINNER, ExpertiseLevel.INTERMEDIATE, ExpertiseLevel.EXPERT]
trust_levels = [AITrustLevel.VERY_DISTRUSTING, AITrustLevel.NEUTRAL, AITrustLevel.VERY_TRUSTING]
scale_levels = [ScaleLevel.LOW, ScaleLevel.MEDIUM, ScaleLevel.HIGH]
```

---

## ğŸ“ˆ æ€§èƒ½æŒ‡æ ‡ä¸æ•ˆæœè¯„ä¼°

### ç³»ç»Ÿæ€§èƒ½
- **å¹³å‡å¤„ç†æ—¶é—´**: 7-8ç§’/æ¬¡è¿è¡Œ
- **å†…å­˜ä½¿ç”¨**: éšå¹¶å‘äººæ ¼æ•°é‡çº¿æ€§å¢é•¿
- **MLå‡†ç¡®ç‡**: éšæœºæ£®æ—æ¨¡å‹è¾¾åˆ°98.36%å‡†ç¡®ç‡
- **å¯é‡ç°æ€§**: ç›¸åŒéšæœºç§å­äº§ç”Ÿä¸€è‡´ç»“æœ

### å¿ƒç†å­¦çœŸå®æ€§éªŒè¯
- **äººæ ¼å·®å¼‚æ€§**: 81ç§äººæ ¼ç»„åˆå±•ç°æ˜¾è‘—ä¸åŒçš„å†³ç­–æ¨¡å¼
- **é‡è¡¨ä¸€è‡´æ€§**: NCSå’ŒGSEé‡è¡¨åˆ†æ•°ä¸è¡Œä¸ºè¡¨ç°é«˜åº¦ä¸€è‡´
- **ä¿¡ä»»æ°´å¹³å½±å“**: AIä¿¡ä»»åº¦æ˜¾è‘—å½±å“é‡‡çº³å†³ç­–
- **è®¤çŸ¥è´Ÿè·ä½“ç°**: é«˜è®¤çŸ¥éœ€æ±‚è€…æä¾›æ›´è¯¦ç»†å’Œå¤æ‚çš„åˆ†æ
- **æƒ…æ„ŸçœŸå®æ€§**: äººæ ¼è¡¨ç°å‡ºçœŸå®çš„æƒ…æ„Ÿååº”å’Œå†…åœ¨å†²çª

### å®éªŒç»“æœç¤ºä¾‹
```
=== æ¨¡æ‹Ÿåˆ†æ ===
æˆåŠŸè¿è¡Œæ€»æ•°: 81
å¹³å‡å¤„ç†æ—¶é—´: 7.84s

å†³ç­–åˆ†å¸ƒ:
  REJECT: 45 (55.6%)
  ACCEPT: 36 (44.4%)

ä¸“ä¸šæ°´å¹³æ¨¡å¼:
  beginner_REJECT: 18
  intermediate_REJECT: 15
  expert_REJECT: 12
  beginner_ACCEPT: 9
  intermediate_ACCEPT: 12
  expert_ACCEPT: 15

ä¿¡ä»»æ°´å¹³æ¨¡å¼:
  trust_-2_REJECT: 25
  trust_0_REJECT: 12
  trust_2_REJECT: 8
  trust_-2_ACCEPT: 2
  trust_0_ACCEPT: 15
  trust_2_ACCEPT: 19

å¿ƒç†é‡è¡¨æ¨¡å¼:
  ncs_Low_REJECT: 20
  ncs_Medium_REJECT: 15
  ncs_High_REJECT: 10
  gse_Low_ACCEPT: 8
  gse_Medium_ACCEPT: 14
  gse_High_ACCEPT: 14
```

---

## ğŸ”® æœªæ¥å¢å¼ºæ–¹å‘

### æŠ€æœ¯ä¼˜åŒ–
1. **å¹¶è¡Œå¤„ç†**: å®ç°å¤šè¿›ç¨‹/å¤šçº¿ç¨‹å¹¶è¡Œæ‰§è¡Œ
2. **ç¼“å­˜æœºåˆ¶**: ç¼“å­˜LLMå“åº”ä»¥æé«˜æ€§èƒ½
3. **æ‰¹é‡API**: ä¼˜åŒ–APIè°ƒç”¨å‡å°‘å»¶è¿Ÿ
4. **å†…å­˜ä¼˜åŒ–**: å¤§è§„æ¨¡å®éªŒçš„å†…å­˜ç®¡ç†
5. **æ¨¡å‹ä¼˜åŒ–**: æ¢ç´¢æ›´å…ˆè¿›çš„LLMæ¨¡å‹

### åŠŸèƒ½æ‰©å±•
1. **æ›´å¤šå¿ƒç†é‡è¡¨**: é›†æˆå¤§äº”äººæ ¼ã€é£é™©åå¥½ã€å†³ç­–é£æ ¼ç­‰é‡è¡¨
2. **åŠ¨æ€å­¦ä¹ **: äººæ ¼åŸºäºç»éªŒæ›´æ–°å†³ç­–æ¨¡å¼
3. **æƒ…å¢ƒå› ç´ **: æ·»åŠ å¸‚åœºæ¡ä»¶ã€ç›‘ç®¡ç¯å¢ƒã€æ—¶é—´å‹åŠ›ç­‰ä¸Šä¸‹æ–‡
4. **å¤šæ¨¡æ€è¾“å…¥**: æ”¯æŒæ–‡æ¡£ã€å›¾åƒç­‰å¤šç§è¾“å…¥ç±»å‹
5. **å¯è§†åŒ–åˆ†æ**: å†³ç­–æ ‘å’Œæ¨¡å¼åˆ†æå·¥å…·

### ç ”ç©¶åº”ç”¨
1. **A/Bæµ‹è¯•**: ä¸åŒAIç•Œé¢è®¾è®¡çš„ç”¨æˆ·æ¥å—åº¦ç ”ç©¶
2. **æ”¿ç­–åˆ†æ**: ç›‘ç®¡æ”¿ç­–å¯¹äººç±»å†³ç­–è¡Œä¸ºçš„å½±å“
3. **åŸ¹è®­ç³»ç»Ÿ**: åŸºäºå¿ƒç†ç‰¹å¾çš„ä¸ªæ€§åŒ–åŸ¹è®­æ–¹æ¡ˆ
4. **é£é™©è¯„ä¼°**: äººæœºåä½œä¸­çš„ç³»ç»Ÿæ€§åå·®è¯†åˆ«
5. **è¡Œä¸ºé¢„æµ‹**: é¢„æµ‹ä¸åŒäººæ ¼åœ¨æ–°æƒ…å¢ƒä¸­çš„è¡Œä¸º

---

## ğŸ“š æŠ€æœ¯ä¾èµ–

### æ ¸å¿ƒä¾èµ–
```python
langchain==0.1.0          # LangChainæ¡†æ¶
langchain-openai==0.0.5   # OpenAIé›†æˆ
openai==1.6.1             # OpenAI APIå®¢æˆ·ç«¯
pandas==2.1.4             # æ•°æ®å¤„ç†
scikit-learn==1.3.2       # æœºå™¨å­¦ä¹ 
tqdm==4.66.1              # è¿›åº¦æ¡
joblib==1.3.2             # æ¨¡å‹åºåˆ—åŒ–
numpy==1.24.3             # æ•°å€¼è®¡ç®—
```

### å®Œæ•´ä¾èµ–å®‰è£…
```bash
pip install langchain langchain-openai openai pandas scikit-learn tqdm joblib numpy
```

---

## ğŸ“ æŠ€æœ¯æ”¯æŒ

### æ•…éšœæ’é™¤
1. **APIè¿æ¥é—®é¢˜**: æ£€æŸ¥ç½‘ç»œè¿æ¥å’ŒAPIå¯†é’¥
2. **å†…å­˜ä¸è¶³**: å‡å°‘å¹¶å‘äººæ ¼æ•°é‡æˆ–æ¡ˆä¾‹æ•°é‡
3. **æ¨¡å‹åŠ è½½å¤±è´¥**: ç¡®è®¤æ¨¡å‹æ–‡ä»¶è·¯å¾„å’Œæ ¼å¼æ­£ç¡®
4. **ç»“æœå¼‚å¸¸**: æ£€æŸ¥æ•°æ®é¢„å¤„ç†å’Œæ ‡ç­¾ç¼–ç ä¸€è‡´æ€§
5. **æç¤ºå·¥ç¨‹é—®é¢˜**: ç¡®ä¿å¿ƒç†ç‰¹å¾é…ç½®æ­£ç¡®

### è°ƒè¯•æ¨¡å¼
```python
# å¯ç”¨è¯¦ç»†æ—¥å¿—
import logging
logging.basicConfig(level=logging.DEBUG)

# å‡å°‘æµ‹è¯•è§„æ¨¡
python main.py --cases 1 --personas 1 --verbose

# æ£€æŸ¥äººæ ¼é…ç½®
python persona_config.py
```

### æ€§èƒ½ç›‘æ§
```python
# ç›‘æ§å¤„ç†æ—¶é—´
results_df = pd.DataFrame(results)
print(f"å¹³å‡å¤„ç†æ—¶é—´: {results_df['processing_time'].mean():.2f}s")
print(f"æœ€é•¿å¤„ç†æ—¶é—´: {results_df['processing_time'].max():.2f}s")

# ç›‘æ§æˆåŠŸç‡
success_rate = len(results_df[results_df['error'].isna()]) / len(results_df)
print(f"æˆåŠŸç‡: {success_rate:.2%}")
```

---

## ğŸ¯ ç³»ç»Ÿç‰¹è‰²æ€»ç»“

### å¿ƒç†å­¦ç†è®ºé©±åŠ¨
1. **åŒè¿‡ç¨‹ç†è®º**: å®Œæ•´å®ç°å¿«æ€è€ƒvsæ…¢æ€è€ƒæœºåˆ¶
2. **å¿ƒç†é‡è¡¨**: NCS-18å’ŒGSE-10çš„ç§‘å­¦å®ç°
3. **äººæ ¼å·®å¼‚åŒ–**: 81ç§ç»„åˆäº§ç”Ÿæ˜¾è‘—ä¸åŒçš„è¡Œä¸ºæ¨¡å¼
4. **æƒ…æ„ŸçœŸå®æ€§**: çœŸå®çš„äººç±»æƒ…æ„Ÿååº”å’Œå†…åœ¨å†²çª

### æŠ€æœ¯åˆ›æ–°äº®ç‚¹
1. **å¢å¼ºæç¤ºå·¥ç¨‹**: å¿ƒç†å­¦é©±åŠ¨çš„å¤æ‚äººæ ¼èº«ä»½è®¾å®š
2. **åŠ¨æ€é€‚åº”æœºåˆ¶**: åŸºäºå¿ƒç†ç‰¹å¾çš„å®æ—¶å†³ç­–è°ƒæ•´
3. **å¤šæ™ºèƒ½ä½“æ¶æ„**: å¿«æ€è€ƒå’Œæ…¢æ€è€ƒçš„ç‹¬ç«‹å®ç°
4. **ç»¼åˆè¯„ä¼°ç³»ç»Ÿ**: å¤šç»´åº¦å†³ç­–è¿‡ç¨‹å®Œæ•´æ•è·

### å®éªŒä»·å€¼
1. **è¡Œä¸ºç ”ç©¶**: ä¸ºäººæœºäº¤äº’ç ”ç©¶æä¾›å¼ºå¤§å®éªŒå¹³å°
2. **AIä¼¦ç†**: ç†è§£ä¸åŒäººç¾¤å¯¹AIçš„æ¥å—å’Œä¿¡ä»»æ¨¡å¼
3. **å†³ç­–ç§‘å­¦**: æ·±å…¥æ´å¯Ÿäººç±»å†³ç­–åˆ¶å®šçš„å¿ƒç†æœºåˆ¶
4. **åº”ç”¨æ½œåŠ›**: å¹¿æ³›çš„å•†ä¸šå’Œå­¦æœ¯åº”ç”¨å‰æ™¯

---

æœ¬æ–‡æ¡£æ¶µç›–äº†LLMæ™ºèƒ½ä½“äººç±»è¡Œä¸ºæ¨¡æ‹Ÿç³»ç»Ÿçš„å®Œæ•´æŠ€æœ¯å®ç°å’Œæœ€æ–°ä¼˜åŒ–ã€‚ç³»ç»ŸæˆåŠŸç»“åˆäº†å¿ƒç†å­¦ç†è®ºä¸äººå·¥æ™ºèƒ½æŠ€æœ¯ï¼Œé€šè¿‡å¢å¼ºçš„æç¤ºå·¥ç¨‹å®ç°äº†é«˜åº¦çœŸå®çš„äººç±»å¿ƒç†è¡Œä¸ºæ¨¡æ‹Ÿï¼Œä¸ºäººæœºäº¤äº’ç ”ç©¶æä¾›äº†å¼ºå¤§è€Œå…ˆè¿›çš„å®éªŒå¹³å°ã€‚

**æ–‡æ¡£ç‰ˆæœ¬**: v2.0  
**æœ€åæ›´æ–°**: 2025å¹´7æœˆ10æ—¥  
**ç»´æŠ¤è€…**: Claude Code Assistant  
**ä¸»è¦æ›´æ–°**: å¢å¼ºçš„å¿ƒç†å­¦æç¤ºå·¥ç¨‹ç³»ç»Ÿï¼Œå®Œæ•´çš„å¿ƒç†é‡è¡¨å®ç°ï¼ŒåŠ¨æ€å¿ƒç†é€‚åº”æœºåˆ¶
#!/usr/bin/env python3
"""
åˆ†æä¸åŒpersonaä¸‹æ¥å—AIå»ºè®®çš„æ¯”ä¾‹å’Œå†³ç­–åˆ‡æ¢æ¨¡å¼
"""

import pandas as pd
import json
import sys
from typing import Dict, Any
import matplotlib.pyplot as plt
import seaborn as sns
from collections import defaultdict

def load_simulation_results(filepath: str) -> pd.DataFrame:
    """Load simulation results from CSV file"""
    try:
        df = pd.read_csv(filepath)
        print(f"Loaded {len(df)} simulation results from {filepath}")
        return df
    except Exception as e:
        print(f"Error loading results: {e}")
        return pd.DataFrame()

def analyze_ai_acceptance_by_persona(df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æä¸åŒpersonaç±»å‹ä¸‹AIå»ºè®®çš„æ¥å—ç‡"""
    
    # æ¸…ç†æ•°æ® - åªä¿ç•™æˆåŠŸçš„è¿è¡Œ
    df_clean = df[df['final_decision_choice'].notna()].copy()
    
    if len(df_clean) == 0:
        print("No valid results to analyze")
        return {}
    
    print(f"\n=== AIå»ºè®®æ¥å—ç‡åˆ†æ ===")
    print(f"æœ‰æ•ˆç»“æœæ•°é‡: {len(df_clean)}")
    
    # æ€»ä½“æ¥å—ç‡
    total_accept = len(df_clean[df_clean['final_decision_choice'] == 'ACCEPT'])
    total_reject = len(df_clean[df_clean['final_decision_choice'] == 'REJECT'])
    overall_acceptance_rate = total_accept / len(df_clean) * 100
    
    print(f"æ€»ä½“AIå»ºè®®æ¥å—ç‡: {overall_acceptance_rate:.1f}% ({total_accept}/{len(df_clean)})")
    print(f"æ€»ä½“AIå»ºè®®æ‹’ç»ç‡: {100-overall_acceptance_rate:.1f}% ({total_reject}/{len(df_clean)})")
    
    analysis = {
        'overall_stats': {
            'total_cases': len(df_clean),
            'accept_count': total_accept,
            'reject_count': total_reject,
            'acceptance_rate': overall_acceptance_rate
        }
    }
    
    # æŒ‰ä¸“ä¸šæ°´å¹³åˆ†æ
    if 'expertise_level' in df_clean.columns:
        print(f"\n--- æŒ‰ä¸“ä¸šæ°´å¹³åˆ†æ ---")
        expertise_analysis = {}
        for expertise in df_clean['expertise_level'].unique():
            subset = df_clean[df_clean['expertise_level'] == expertise]
            accept_count = len(subset[subset['final_decision_choice'] == 'ACCEPT'])
            acceptance_rate = accept_count / len(subset) * 100
            expertise_analysis[expertise] = {
                'total_cases': len(subset),
                'accept_count': accept_count,
                'acceptance_rate': acceptance_rate
            }
            print(f"  {expertise}: {acceptance_rate:.1f}% ({accept_count}/{len(subset)})")
        analysis['expertise_analysis'] = expertise_analysis
    
    # æŒ‰AIä¿¡ä»»æ°´å¹³åˆ†æ
    if 'ai_trust_level' in df_clean.columns:
        print(f"\n--- æŒ‰AIä¿¡ä»»æ°´å¹³åˆ†æ ---")
        trust_analysis = {}
        for trust_level in sorted(df_clean['ai_trust_level'].unique()):
            subset = df_clean[df_clean['ai_trust_level'] == trust_level]
            accept_count = len(subset[subset['final_decision_choice'] == 'ACCEPT'])
            acceptance_rate = accept_count / len(subset) * 100
            trust_analysis[trust_level] = {
                'total_cases': len(subset),
                'accept_count': accept_count,
                'acceptance_rate': acceptance_rate
            }
            trust_desc = {-2: "éå¸¸ä¸ä¿¡ä»»", -1: "æœ‰äº›ä¸ä¿¡ä»»", 0: "ä¸­ç«‹", 1: "æœ‰äº›ä¿¡ä»»", 2: "éå¸¸ä¿¡ä»»"}
            print(f"  {trust_level} ({trust_desc.get(trust_level, 'Unknown')}): {acceptance_rate:.1f}% ({accept_count}/{len(subset)})")
        analysis['trust_analysis'] = trust_analysis
    
    # æŒ‰è®¤çŸ¥éœ€æ±‚åˆ†æ (å¦‚æœæœ‰NCSåˆ†æ•°)
    if 'ncs_score' in df_clean.columns and df_clean['ncs_score'].notna().any():
        print(f"\n--- æŒ‰è®¤çŸ¥éœ€æ±‚æ°´å¹³åˆ†æ ---")
        # åˆ›å»ºè®¤çŸ¥éœ€æ±‚æ°´å¹³åˆ†ç±»
        df_clean['ncs_level'] = pd.cut(df_clean['ncs_score'], 
                                     bins=[0, 59, 74, 90], 
                                     labels=['Low', 'Medium', 'High'])
        
        ncs_analysis = {}
        for ncs_level in ['Low', 'Medium', 'High']:
            subset = df_clean[df_clean['ncs_level'] == ncs_level]
            if len(subset) > 0:
                accept_count = len(subset[subset['final_decision_choice'] == 'ACCEPT'])
                acceptance_rate = accept_count / len(subset) * 100
                ncs_analysis[ncs_level] = {
                    'total_cases': len(subset),
                    'accept_count': accept_count,
                    'acceptance_rate': acceptance_rate
                }
                print(f"  {ncs_level} NCS: {acceptance_rate:.1f}% ({accept_count}/{len(subset)})")
        analysis['ncs_analysis'] = ncs_analysis
    
    # æŒ‰è‡ªæˆ‘æ•ˆèƒ½æ„Ÿåˆ†æ (å¦‚æœæœ‰GSEåˆ†æ•°)
    if 'gse_score' in df_clean.columns and df_clean['gse_score'].notna().any():
        print(f"\n--- æŒ‰è‡ªæˆ‘æ•ˆèƒ½æ„Ÿæ°´å¹³åˆ†æ ---")
        # åˆ›å»ºè‡ªæˆ‘æ•ˆèƒ½æ„Ÿæ°´å¹³åˆ†ç±»
        df_clean['gse_level'] = pd.cut(df_clean['gse_score'], 
                                     bins=[0, 29, 34, 40], 
                                     labels=['Low', 'Medium', 'High'])
        
        gse_analysis = {}
        for gse_level in ['Low', 'Medium', 'High']:
            subset = df_clean[df_clean['gse_level'] == gse_level]
            if len(subset) > 0:
                accept_count = len(subset[subset['final_decision_choice'] == 'ACCEPT'])
                acceptance_rate = accept_count / len(subset) * 100
                gse_analysis[gse_level] = {
                    'total_cases': len(subset),
                    'accept_count': accept_count,
                    'acceptance_rate': acceptance_rate
                }
                print(f"  {gse_level} GSE: {acceptance_rate:.1f}% ({accept_count}/{len(subset)})")
        analysis['gse_analysis'] = gse_analysis
    
    return analysis

def analyze_decision_switching(df: pd.DataFrame) -> Dict[str, Any]:
    """åˆ†æå†³ç­–åˆ‡æ¢æ¨¡å¼ - åˆå§‹å†³ç­–ä¸æœ€ç»ˆå†³ç­–çš„å¯¹æ¯”"""
    
    df_clean = df[df['final_decision_choice'].notna() & df['initial_decision'].notna()].copy()
    
    if len(df_clean) == 0:
        print("No valid decision data to analyze switching patterns")
        return {}
    
    print(f"\n=== å†³ç­–åˆ‡æ¢æ¨¡å¼åˆ†æ ===")
    
    # åˆ›å»ºå†³ç­–å¯¹æ¯”
    df_clean['decision_switch'] = df_clean.apply(lambda row: 
        'Switched' if (
            (row['initial_decision'] == 'Approve' and row['final_decision_choice'] == 'REJECT') or
            (row['initial_decision'] == 'Reject' and row['final_decision_choice'] == 'ACCEPT')
        ) else 'Consistent', axis=1)
    
    switch_count = len(df_clean[df_clean['decision_switch'] == 'Switched'])
    consistent_count = len(df_clean[df_clean['decision_switch'] == 'Consistent'])
    switch_rate = switch_count / len(df_clean) * 100
    
    print(f"å†³ç­–åˆ‡æ¢ç‡: {switch_rate:.1f}% ({switch_count}/{len(df_clean)})")
    print(f"å†³ç­–ä¸€è‡´ç‡: {100-switch_rate:.1f}% ({consistent_count}/{len(df_clean)})")
    
    switching_analysis = {
        'overall_switching': {
            'total_cases': len(df_clean),
            'switched_count': switch_count,
            'consistent_count': consistent_count,
            'switch_rate': switch_rate
        }
    }
    
    # æŒ‰ä¸“ä¸šæ°´å¹³åˆ†æåˆ‡æ¢æ¨¡å¼
    if 'expertise_level' in df_clean.columns:
        print(f"\n--- æŒ‰ä¸“ä¸šæ°´å¹³çš„åˆ‡æ¢æ¨¡å¼ ---")
        expertise_switching = {}
        for expertise in df_clean['expertise_level'].unique():
            subset = df_clean[df_clean['expertise_level'] == expertise]
            switched = len(subset[subset['decision_switch'] == 'Switched'])
            switch_rate_exp = switched / len(subset) * 100
            expertise_switching[expertise] = {
                'total_cases': len(subset),
                'switched_count': switched,
                'switch_rate': switch_rate_exp
            }
            print(f"  {expertise}: {switch_rate_exp:.1f}% switched ({switched}/{len(subset)})")
        switching_analysis['expertise_switching'] = expertise_switching
    
    # æŒ‰AIä¿¡ä»»æ°´å¹³åˆ†æåˆ‡æ¢æ¨¡å¼
    if 'ai_trust_level' in df_clean.columns:
        print(f"\n--- æŒ‰AIä¿¡ä»»æ°´å¹³çš„åˆ‡æ¢æ¨¡å¼ ---")
        trust_switching = {}
        for trust_level in sorted(df_clean['ai_trust_level'].unique()):
            subset = df_clean[df_clean['ai_trust_level'] == trust_level]
            switched = len(subset[subset['decision_switch'] == 'Switched'])
            switch_rate_trust = switched / len(subset) * 100
            trust_switching[trust_level] = {
                'total_cases': len(subset),
                'switched_count': switched,
                'switch_rate': switch_rate_trust
            }
            trust_desc = {-2: "éå¸¸ä¸ä¿¡ä»»", -1: "æœ‰äº›ä¸ä¿¡ä»»", 0: "ä¸­ç«‹", 1: "æœ‰äº›ä¿¡ä»»", 2: "éå¸¸ä¿¡ä»»"}
            print(f"  {trust_level} ({trust_desc.get(trust_level, 'Unknown')}): {switch_rate_trust:.1f}% switched ({switched}/{len(subset)})")
        switching_analysis['trust_switching'] = trust_switching
    
    return switching_analysis

def generate_summary_report(acceptance_analysis: Dict[str, Any], 
                          switching_analysis: Dict[str, Any]) -> str:
    """ç”Ÿæˆæ€»ç»“æŠ¥å‘Š"""
    
    report = "\n" + "="*80 + "\n"
    report += "                    PERSONAè¡Œä¸ºåˆ†ææŠ¥å‘Š\n"
    report += "="*80 + "\n"
    
    # æ€»ä½“ç»Ÿè®¡
    if 'overall_stats' in acceptance_analysis:
        stats = acceptance_analysis['overall_stats']
        report += f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:\n"
        report += f"   â€¢ æ€»æ¡ˆä¾‹æ•°: {stats['total_cases']}\n"
        report += f"   â€¢ AIå»ºè®®æ¥å—ç‡: {stats['acceptance_rate']:.1f}%\n"
        
    if 'overall_switching' in switching_analysis:
        switch_stats = switching_analysis['overall_switching']
        report += f"   â€¢ å†³ç­–åˆ‡æ¢ç‡: {switch_stats['switch_rate']:.1f}%\n"
    
    # ä¸“ä¸šæ°´å¹³å½±å“
    if 'expertise_analysis' in acceptance_analysis:
        report += f"\nğŸ“ ä¸“ä¸šæ°´å¹³å¯¹AIæ¥å—åº¦çš„å½±å“:\n"
        exp_data = acceptance_analysis['expertise_analysis']
        for level in ['beginner', 'intermediate', 'expert']:
            if level in exp_data:
                rate = exp_data[level]['acceptance_rate']
                report += f"   â€¢ {level.title()}: {rate:.1f}% æ¥å—ç‡\n"
    
    # AIä¿¡ä»»æ°´å¹³å½±å“
    if 'trust_analysis' in acceptance_analysis:
        report += f"\nğŸ¤– AIä¿¡ä»»æ°´å¹³å¯¹æ¥å—åº¦çš„å½±å“:\n"
        trust_data = acceptance_analysis['trust_analysis']
        trust_labels = {-2: "éå¸¸ä¸ä¿¡ä»»", 0: "ä¸­ç«‹", 2: "éå¸¸ä¿¡ä»»"}
        for level in [-2, 0, 2]:
            if level in trust_data:
                rate = trust_data[level]['acceptance_rate']
                report += f"   â€¢ {trust_labels[level]}: {rate:.1f}% æ¥å—ç‡\n"
    
    # å¿ƒç†é‡è¡¨å½±å“
    if 'ncs_analysis' in acceptance_analysis:
        report += f"\nğŸ§  è®¤çŸ¥éœ€æ±‚æ°´å¹³å½±å“:\n"
        ncs_data = acceptance_analysis['ncs_analysis']
        for level in ['Low', 'Medium', 'High']:
            if level in ncs_data:
                rate = ncs_data[level]['acceptance_rate']
                report += f"   â€¢ {level} NCS: {rate:.1f}% æ¥å—ç‡\n"
    
    if 'gse_analysis' in acceptance_analysis:
        report += f"\nğŸ’ª è‡ªæˆ‘æ•ˆèƒ½æ„Ÿæ°´å¹³å½±å“:\n"
        gse_data = acceptance_analysis['gse_analysis']
        for level in ['Low', 'Medium', 'High']:
            if level in gse_data:
                rate = gse_data[level]['acceptance_rate']
                report += f"   â€¢ {level} GSE: {rate:.1f}% æ¥å—ç‡\n"
    
    # å†³ç­–åˆ‡æ¢æ¨¡å¼
    if 'trust_switching' in switching_analysis:
        report += f"\nğŸ”„ å†³ç­–åˆ‡æ¢æ¨¡å¼ (æŒ‰AIä¿¡ä»»æ°´å¹³):\n"
        switch_data = switching_analysis['trust_switching']
        trust_labels = {-2: "éå¸¸ä¸ä¿¡ä»»", 0: "ä¸­ç«‹", 2: "éå¸¸ä¿¡ä»»"}
        for level in [-2, 0, 2]:
            if level in switch_data:
                rate = switch_data[level]['switch_rate']
                report += f"   â€¢ {trust_labels[level]}: {rate:.1f}% åˆ‡æ¢ç‡\n"
    
    report += "\n" + "="*80 + "\n"
    return report

def main():
    """Main analysis function"""
    
    # Check if results file path is provided
    if len(sys.argv) < 2:
        print("Usage: python analyze_persona_decisions.py <results_csv_file>")
        print("Looking for latest results file...")
        
        # Try to find the latest results file
        import glob
        results_files = glob.glob("results/simulation_results_*.csv")
        if results_files:
            latest_file = max(results_files)
            print(f"Found latest file: {latest_file}")
        else:
            print("No results files found. Please run a simulation first.")
            return
    else:
        latest_file = sys.argv[1]
    
    # Load and analyze results
    df = load_simulation_results(latest_file)
    if df.empty:
        return
    
    # Perform analyses
    acceptance_analysis = analyze_ai_acceptance_by_persona(df)
    switching_analysis = analyze_decision_switching(df)
    
    # Generate and display report
    report = generate_summary_report(acceptance_analysis, switching_analysis)
    print(report)
    
    # Save detailed analysis to JSON
    detailed_analysis = {
        'ai_acceptance_analysis': acceptance_analysis,
        'decision_switching_analysis': switching_analysis,
        'analysis_metadata': {
            'source_file': latest_file,
            'total_records': len(df),
            'analysis_timestamp': pd.Timestamp.now().isoformat()
        }
    }
    
    # Convert numpy/pandas types to native Python types for JSON serialization
    def convert_types(obj):
        if isinstance(obj, dict):
            return {str(k): convert_types(v) for k, v in obj.items()}
        elif isinstance(obj, (list, tuple)):
            return [convert_types(item) for item in obj]
        elif hasattr(obj, 'item'):  # numpy types
            return obj.item()
        elif pd.isna(obj):
            return None
        else:
            return obj
    
    detailed_analysis = convert_types(detailed_analysis)
    
    output_file = latest_file.replace('.csv', '_persona_analysis.json')
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(detailed_analysis, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“ è¯¦ç»†åˆ†æç»“æœå·²ä¿å­˜åˆ°: {output_file}")

if __name__ == "__main__":
    main()